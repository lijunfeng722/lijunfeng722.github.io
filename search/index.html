<!DOCTYPE html>
<html lang="en">




<head><meta name="generator" content="Hexo 3.8.0">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  
      <title>Search - HeiHeiHei</title>
  

  
  
  <meta name="description" content>
  <meta name="author" content="Li JunFeng">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- load loadjs.js -->
  <script src="/libs/loadjs/dist/loadjs.min.js"></script>

<link rel="stylesheet" href="/libs/animate.css/animate.min.css">
  <!-- load lightgallery -->
<link rel="stylesheet" href="/css/lightgallery.css">
<link rel="stylesheet" href="/libs/noty/lib/noty.css">
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  






    <link rel="stylesheet" href="/css/taurus.css">
    
        <link rel="stylesheet" href="/css/scheme-taurus/animations.css">
    


<link rel="stylesheet" href="/.css">

  <!-- load font awesome 5 -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>
  <!-- load mathjax -->
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax//libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <!-- load js-cookie -->
  <script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
    <script src="/js/social-share.min.js"></script>
    <script src="/js/theme.js"></script>

  <!-- include cookie.js -->
  
  

  <!-- include comment system code -->
  
    <script src="//cdn1.lncld.net/static/js/3.6.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/favicon.png">
</head>
<body style="display: flex; flex-direction: column; min-height: 100vh;">

 

<header id="header" class="header">
	<div class="header-title">
		
		<div class="header-logo">
			<a href="/">
				<img src="https://avatars2.githubusercontent.com/u/12017992?s=400&u=722ebc8cc275146695a49b651b96e4eb89a182c1&v=4">
			</a>
		</div>
		<div class="header-text">
			<h1>
				<a href="/">HeiHeiHei</a>
			</h1>
			<subtitle>
				
			</subtitle>
		</div>
		
	</div>
	<div id="header-nav">
		



<nav id="nav">
	
	
	
	<div class="nav-item" id="nav-item-archive">
		
				<div class="nav-icon">
				
			<a href="/archives/" title="Archives">
			<img src="/images/icons/colorful-outlined/archive.svg" alt>
			</a>
		</div>
	</div>
	<div class="nav-item" id="nav-item-search">
		
		<div class="nav-icon active_dot">
		
			<a href="/search/" title="Search">
			<img src="/images/icons/colorful-outlined/search.svg" alt>
			</a>
		</div>
	</div>
	<div class="nav-item" id="nav-item-more">
		<div class="nav-icon">
				<a href="#" onclick="onClickMenuIcon(event);" ontouchstart="onClickMenuIcon(event);">
				<img src="/images/icons/colorful-outlined/menu.svg" alt>
				</a>
		</div>
		<div class="nav-more-menu">
				<i class="far fa-times-circle" id="nav-more-menu-close" onclick="onClickNavMenuClose(event);" ontouchstart="onClickNavMenuClose(event);"></i>
		
		
		<div class="nav-more-item">
				<div class="nav-name">
					<a class="nav-link" href="/categories/Java/">
						<span>Java</span>
					</a>
				</div>
		</div>
		
		<div class="nav-more-item">
				<div class="nav-name">
					<a class="nav-link" href="/categories/Spring-Boot/">
						<span>Spring-boot</span>
					</a>
				</div>
		</div>
		
		<div class="nav-more-item">
				<div class="nav-name">
					<a class="nav-link" href="/categories/Spring-Cloud/">
						<span>Spring-cloud</span>
					</a>
				</div>
		</div>
		
	</div>
	</div>
</nav>

	</div>
</header>

 




  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div style="flex: 1;">
      <style>
    body {
        background-color: white;
    }
</style>
<div class="search-container">
	<input type="text" id="search-form">

	<ul class="cat-list">
		
			<li><a href="/categories/Java/"><img src="/images/Java.svg" alt="Java" onerror="if(this.src != "/images/uncategorized.svg") this.src="/images/uncategorized.svg"" title="Java"></a></li>
		
			<li><a href="/categories/Spring-Boot/"><img src="/images/Spring-Boot.svg" alt="Spring-Boot" onerror="if(this.src != "/images/uncategorized.svg") this.src="/images/uncategorized.svg"" title="Spring-Boot"></a></li>
		
			<li><a href="/categories/Spring-Cloud/"><img src="/images/Spring-Cloud.svg" alt="Spring-Cloud" onerror="if(this.src != "/images/uncategorized.svg") this.src="/images/uncategorized.svg"" title="Spring-Cloud"></a></li>
		
	</ul>

	<div class="archive-cards">
			<div class="Card-archive" style="display:none">
				<div class="Card-body">
					<h3 class="Card-title">
						<a>
						</a>
					</h3>
					<div class="Card-meta">
						<ul>
							<li><i class="fa fa-calendar"></i> <span class="Card-date"></span></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
</div>

<script src="/libs/fuse.js/dist/fuse.min.js"></script>
<script>
	var options = {
		shouldSort: true,
		threshold: 0.4,
		tokenize: true,
		location: 0,
		distance: 100,
		maxPatternLength: 32,
		minMatchCharLength: 2,
		keys: [
			"title",
			"author",
			"tags"
		]
	};
	var s = '[{"title":"Java8 之 Lambda","date":"2019-05-19T09:34:35.000Z","content":"lambda即匿名函数，使用它可以简洁的表示一个行为。由于这个“行为”是可以传递的，Java8的世界变得妙极了~\n\n引言\n简单地看个例子：\n123456@Data@AllArgsConstructorpublic class Apple &#123;    private Integer weight;    private String color;&#125;\n1234567appleList.sort(new Comparator&lt;Apple&gt;() &#123;    @Override    public int compare(Apple a1, Apple a2) &#123;        return a1.getWeight() - a2.getWeight();    &#125;&#125;);System.out.println(appleList);\nsort方法需要传入一个Comparator接口以便进行排序。\n在Java8以前，显然需要传入一个Comparator的实现类，就像上面的代码。\n我们已经习惯了使用匿名类来实现接口，但是这种方式有几个显而易见的缺点：\n\n\n代码量太多，我们真正要关心的只有o1.getWeight() - o2.getWeight()一句，其他的代码都是一些不得不写，但是很繁琐的样板化代码。而且对于阅读代码来说也是写无用信息。\n\n\n如果需要不同的比较器，需要书写多个匿名类。而且，为了复用和清晰，我们就不能使用匿名类，只得将他们提取出来，成为一个个的比较器实现类，这又增加了许多代码的书写，如下所示：\n12345678910111213class AppleComparatorByWeight implements Comparator&lt;Apple&gt;&#123;        public int compare(Apple a1, Apple a2) &#123;            return xxx        &#125;&#125;class AppleComparatorByColor implements Comparator&lt;Apple&gt;&#123;        public int compare(Apple a1, Apple a2) &#123;            return xxx        &#125;&#125;appleList.sort(new AppleComparatorByWeight());appleList.sort(new AppleComparatorByColor());\n\n\n看看Java8是如何解决的：\n1appleList.sort((a1, a2) -&gt; a1.getWeight() - a2.getWeight());\n使用Lambd后，只需要关注真正的业务代码，它自动实现了Comparator接口，并复写了compare方法，我们再也不用写那些讨厌的样板化代码了。代码的语言也变得清晰易懂。\n除了Lambda，使用方法引用，甚至可以进一步将代码简化如下：\n1appleList.sort(comparingInt(Apple::getWeight));\n要复用比较器的情景下，也不需要编写实现类，只需要用lambda。\n1234Comparator&lt;Apple&gt; c1 = (a1, a2) -&gt; a1.getWeight() - a2.getWeight();Comparator&lt;Apple&gt; c2 = (a1, a2) -&gt; a1.getColor().compareTo(a2.getColor());appleList.sort(c1);appleList.sort(c2);\n函数式接口 @FunctionalInterface\n@FunctionalInterface是Java8新引入的一个注解，它可以标记在接口抽象类上，表明此接口抽象类是一个函数式接口。如果该接口抽象类不满足函数式接口的要求，那么编译器将报错。\n\n函数式接口： 该接口抽象类只包含一个抽象方法。（default方法不算抽象方法）\n\n比如刚才的sort方法接收的Comparator接口，就是一个函数式接口，它只有一个compare()抽象方法。\n\n注：如果一个接口复写了Object的方法，并不影响它成为函数式接口。比如Comparator接口还复写了equals方法。\n\n在比如Runnable接口，在JDK8中也被标记上了@FunctionalInterface，因为它只有一个抽象方法：\n1234@FunctionalInterfacepublic interface Runnable &#123;    public abstract void run();&#125;\n那么，函数式接口有什么用呢？\n传递行为，而不是传递值\nJava8中，终于将函数lambda作为一等公民，这意味着，我们可以将“行为”保存到一个变量里；也可以将&quot;行为&quot;作为参数，在方法之间传递。\n我们先自己写一段代码来感受下，如何接收一个行为。\n1234567891011121314151617181920212223@FunctionalInterfaceinterface BufferedReaderProcessor &#123; step 1: 定义一个函数式接口，可以理解为“行为”接口    String process(BufferedReader b) throws IOException;&#125;public class ProcessFileDemo &#123;     step 2: 定义一个方法，来接收“行为”    static String processFile(BufferedReaderProcessor p) throws IOException &#123;        try (BufferedReader br = new BufferedReader(new FileReader(data.txt))) &#123;            return p.process(br);  调用这个行为p，这个“行为”需要一个参数br        &#125;    &#125;    public static void main(String[] args) throws IOException &#123;        step 3: 向processFile()传递行为        String online = processFile(br -&gt; br.readLine());        String twoLines = processFile(br -&gt; br.readLine() + br.readLine());        System.out.println(online:n + online);        System.out.println(twoLines:n + twoLines);    &#125;&#125;\n显然，lambda自动地实现了BufferedReaderProcessor接口并override了process方法。\n在看下其他的例子，\n1234执行一个行为是“打印haha的线程new Thread(()-&gt; System.out.println(haha)).start(); 对于每个apple，执行打印操作appleList.forEach(apple -&gt; System.out.println(apple));\n我们说过Runnable接口是一个FunctionalInterface，那么第一个例子中，lambda显然实现了Runnable的run方法。\n那么，传递给forEach方法的lambda又实现了什么接口呢？\n123456 public interface Iterable&lt;T&gt; default void forEach(Consumer&lt;? super T&gt; action) &#123;     Objects.requireNonNull(action);     for (T t : this)          action.accept(t);&#125;\n可以看到，forEach方法接收一个consumer，那么显然我们传递的apple -&gt; System.out.println(apple)实现了该接口。\n12345@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123;    void accept(T t);     ....&#125;\nConsumer只有一个抽象方法accept。它接收一个t，返回void。\n结合forEach()方法的定义来思考，当我们调用appleList.forEach(apple -&gt; System.out.println(apple));方法时，t其实是list中的每个apple元素，action是打印apple。\n于是，对于每个apple，Consumer(即“打印行为”) accpet了这个apple。\n这里有可能有点绕，其实就像下面:\n123456appleList.forEach(new Consumer&lt;Apple&gt;() &#123;    @Override    public void accept(Apple apple) &#123;        System.out.println(apple);    &#125;&#125;);\nlambda相当于实现了Cousumer接口的accpet方法，然后forEach方法中，对每个元素，都调用accept方法。\nConsumer其实是JDK为我们抽象出了一个通用的函数接口，他将所有接收一个对象，返回void的行为，叫做Consumer。\n又比如Predicate接口\n1234@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123;    boolean test(T t);&#125;\n接收一个对象，返回boolean的行为，叫做Predicate。\n比如我们可以这样：\n1234Object[] objects = appleList.stream()    .filter(apple -&gt; red.equals(apple.getColor()))    .toArray(); 关于stream()请参考下一讲《Java8-Stream》\nfilter方法接收一个Predicate。apple为红色时，返回true。\n那么这条代码将返回appleList中所有红色的苹果。\nJDK中还有许多抽象的行为接口：\n\n\n\n函数式接口\n函数描述符\n说明\n\n\n\n\nPredicate\nT-&gt;boolean\n接收T，返回boolean\n\n\nConsumer\nT-&gt;void\n接收T，返回void\n\n\nFunction&lt;T,R&gt;\nT-&gt;R\n接收T，返回R\n\n\nSupplier\n()-&gt;T\n什么也不接收，返回一个T\n\n\nUnaryOperator\nT-&gt;T\n接收一个T，返回一个T\n\n\nBinaryOperator\n(T,T)-&gt;T\n接收两个T类型对象，返回一个T类型对象\n\n\nBiPredicate&lt;L,R&gt;\n(L,R)-&gt;boolean\n接收T、R，返回boolean\n\n\nBiConsumer&lt;T,U&gt;\n(T,U)-&gt;void\n接收T、U，返回void\n\n\nBiFunction&lt;T,U,R&gt;\n(T,U)-&gt;R\n接收T、U，返回一个R\n\n\n\n还记得上面我们实现的BufferedReaderProcessor吗？\n1234@FunctionalInterfaceinterface BufferedReaderProcessor &#123;     String process(BufferedReader b) throws IOException;&#125;\n它不正是一个Function&lt;BufferedReader,String&gt;吗。TODO 试着修改下之前的代码？\nlambda书写语法\nLambda基本语法是\n\n(parameters) -&gt; expression\n\n或（请注意语句的花括号）\n\n(parameters) -&gt; { statements; }\n\n12345678910111213第一个Lambda具有一个String类型的参数并返回一个int。 没有写return语句，但是已经隐含了return(String s) -&gt; s.length()  它相当于(String s) -&gt; &#123;return s.length();&#125;第二个Lambda有一个Apple类型的参数并返回一个boolean(Apple a) -&gt; a.getWeight() &gt; 150第三个Lambda有两个int类型的参数而没有返回值（void返回）。注意Lambda可以包含多行语句，这里是两行(int x, int y) -&gt; &#123;    System.out.println(Result:);    System.out.println(x+y);&#125;第四个Lambda没有参数，返回一个int() -&gt; 42第五个Lambda有两个Apple类型的参数，返回一个int(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight())\n方法引用\n我们已经知道了，可以通过lambda来implement一个函数式接口，从而省去很多样板化代码。\n另外，通过方法引用的方式，也可以implement一个函数式接口，而且这种方式能进一步简化代码、提高代码易读性。\n123456789101112131415161718192021222324 例一：静态方法引用List&lt;String&gt; strings = Arrays.asList(12, 14, 3, 2); 使用lambda：strings.stream()    .map(str-&gt;Integer.parseInt(str))  （map方法的意思是将每个str映射成一个int）    .toArray(); 使用方法引用strings.stream()    .map(Integer::parseInt)  引用Integer类的静态方法    .toArray(); 例二：任意类型实例方法引用 使用lambda：appleList.stream().map(apple -&gt; apple.toString()).forEach(System.out::println); 使用方法引用appleList.stream()    .map(Apple::toString)  引用appleList中每个元素的toString    .forEach(System.out::println); 例三：现有对象的实例方法引用 使用lambda：appleList.forEach(apple -&gt; System.out.println(apple)); 使用方法引用： appleList.forEach(System.out::println); 引用System.out对象的实例方法println。 传入的参数是每个遍历到的apple\n以上展示了总共的三种方法引用。\n\n静态方法的引用\n任意类型实例方法的引用\n现有对象的方法的引用\n\n需要区别的是后两种，正如实例代码中，第二种方式时，appleList中的每个元素是方法的调用者；而第三种方式时，由于引用的是其他对象的方法，所以appleList中的每个元素成为了该方法的入参。\nps：实例代码中的map方法传入一个Function&lt;T,R&gt;，作用是将一个T类型的流映射成一个R类型的流。关于流的内容请参考下一讲《Java8-Stream》\n进阶：复合lambda\n类比于数学中的函数组合\n123f(x) = x+1g(x) = x*2则 g(f(x)) = (x+1)*2\n可以把多个简单的lambda复合成复杂的表达式。\n函数复合\n123456Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h1 = f.andThen(g); h1 = (x+1)*2Function&lt;Integer, Integer&gt; h2 = f.compose(g); h2 = 2*x+1int result1 = h1.apply(1);  4int result2 = h2.apply(1);  3\n谓词复合\n123456789Predicate&lt;Apple&gt; redApple = apple -&gt; red.equals(apple.getColor());Predicate&lt;Apple&gt; notRedApple = redApple.negate();Predicate&lt;Apple&gt; redAndHeavyApple = redApple.and(a -&gt; a.getWeight() &gt; 150);Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen =    redApple.and(a -&gt; a.getWeight() &gt; 150)    .or(a -&gt; green.equals(a.getColor()));  (red &amp;&amp; &gt;150)||green请注意， and和or方法是按照在表达式链中的位置，从左向右确定优先级的。因此， a.or(b).and(c)可以看作(a || b) &amp;&amp; c\n比较器复合\n逆序\n1appleList.sort( comparing(Apple::getWeight).reversed() );\n比较器链\n12345appleList.sort( \t\t\t\tcomparing(Apple::getWeight)                .reversed()                .thenComparing(Apple::getCountry)              );\nlambda的注意事项\nlambda与异常\n请注意，任何函数式接口都不允许抛出受检异常（checked exception）。如果你需要Lambda\n表达式来抛出异常，有两种办法：定义一个自己的函数式接口，并声明受检异常，或者把Lambda\n包在一个trycatch块中。\n\n对于自己的函数式接口\n\n比如，我们介绍了一个新的函数式接口BufferedReaderProcessor，它显式声明了一个IOException：\n12345@FunctionalInterfacepublic interface BufferedReaderProcessor &#123;\tString process(BufferedReader b) throws IOException;&#125;BufferedReaderProcessor p = (BufferedReader br) -&gt; br.readLine();\n\n把Lambda在一个trycatch块中\n\n如果你使用一个接受函数式接口的API，比如Function&lt;T, R&gt;，没有办法自己声明抛出Exception。这种情况下，你可以显式捕捉受检异常：\n12345678Function&lt;BufferedReader, String&gt; f = (BufferedReader b) -&gt; &#123;\ttry &#123;\t\treturn b.readLine();\t&#125;\tcatch(IOException e) &#123;\t\tthrow new RuntimeException(e);\t&#125;&#125;;\n同样的 Lambda，不同的函数式接口\n同一个Lambda表达式就可以对应不同的函数式接口，只要它们的方法签名能够兼容 。\n比如我们自己写的BufferedReaderProcessor其实就是一个Function&lt;BufferedReader, String&gt;\n1234@FunctionalInterfaceinterface BufferedReaderProcessor &#123;    String process(BufferedReader b) throws IOException;&#125;\n于是相同的lambda可以同时对应BufferedReaderProcessor和Function&lt;BufferedReader, String&gt;\n12BufferedReaderProcessor p1 = br -&gt; br.readLine();Function&lt;BufferedReader, String&gt; p2 = br -&gt; br.readLine();\n再比如：\n123456Comparator&lt;Apple&gt; c1 =\t(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());ToIntBiFunction&lt;Apple, Apple&gt; c2 =\t(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());BiFunction&lt;Apple, Apple, Integer&gt; c3 =\t(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());\n(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());的方法签名为（Apple, Apple） -&gt; Integer,所以它同时符合三种函数式接口的签名\n\nComparator:   ( T, T ) -&gt;int\nToIntBiFunction： （T, U）-&gt; int\nBiFunction: ( T, U, R ) -&gt; R\n\n另外，如果一个Lambda的主体是一个语句表达式， 它就和一个返回void的函数描述符兼容（当然需要参数列表也兼容）。例如，以下两行都是合法的，尽管List的add方法返回了一个boolean，而不是Consumer上下文（T -&gt; void）所要求的void：\n1234 Predicate返回了一个booleanPredicate&lt;String&gt; p = s -&gt; list.add(s); Consumer返回了一个voidConsumer&lt;String&gt; b = s -&gt; list.add(s);\n类型推断\n编译器可以了解Lambda表达式的参数类型，这样就可在Lambda语法中省去标注参数类型\n1234567Comparator&lt;Apple&gt; c = (Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());Comparator&lt;Apple&gt; c = (a1, a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); 当Lambda仅有一个类型需要推断的参数时，参数名称两边的括号也可以省略appleList.forEach( a -&gt; System.out::println); forEach(Consumer&lt;T&gt;) -&gt; appleList -&gt; Apple -&gt; T is Apple -&gt; a为Apple\n局部变量\nLambda表达式引用的局部变量必须是 final，或事实上是final 的\n下面的代码无法编译，因为portNumber被赋值两次\n123int portNumber = 1337;Runnable r = () -&gt; System.out.println(portNumber);portNumber = 31337; 如果去掉这一句，则可以正常编译\n\n你可能会问自己，为什么局部变量有这些限制。\n第一，实例变量和局部变量背后的实现有一个关键不同。实例变量都存储在堆中，而局部变量则保存在栈上。如果Lambda可以直接访问局部变量，而且Lambda是在一个线程中使用的，则使用Lambda的线程，可能会在分配该变量的线程将这个变量收回之后，去访问该变量。因此， Java在访问自由局部变量时，实际上是在访问它的副本，而不是访问原始变量。如果局部变量仅仅赋值一次那就没有什么区别了——因此就有了\n这个限制。\n第二，这一限制不鼓励你使用改变外部变量的典型命令式编程模式（我们会在以后解释，这种模式会阻碍很容易做到的并行处理）\n\n测验\n函数式接口\n\n\n\n布尔表达式\n(List list) -&gt; list.isEmpty()\nPredicate&lt;List&gt;\n\n\n\n\n创建对象\n() -&gt; new Apple(10)\nSupplier\n\n\n消费一个对象\n(Apple a) -&gt; System.out.println(a.getWeight())\nConsumer\n\n\n从一个对象中选择提取\n(String s) -&gt; s.length()\nFunction&lt;String, Integer&gt;或ToIntFunction\n\n\n合并两个值\n(int a, int b) -&gt; a * b\nIntBinaryOperator\n\n\n比较两个对象\n(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight())\nComparator或BiFunction&lt;Apple, Apple, Integer&gt; 或 ToIntBiFunction&lt;Apple, Apple\n\n\n\n下面哪些接口是函数式接口？\n12345678public interface Adder&#123;\tint add(int a, int b);&#125;public interface SmartAdder extends Adder&#123;\tint add(double a, double b);&#125;public interface Nothing&#123;&#125;\n答案：只有Adder是函数式接口。\nSmartAdder不是函数式接口，因为它定义了两个叫作add的抽象方法（其中一个是从\nAdder那里继承来的）。\nNothing也不是函数式接口，因为它没有声明抽象方法。\nLambda语法\n根据上述语法规则，以下哪个不是有效的Lambda表达式？\n12345(1) () -&gt; &#123;&#125;(2) () -&gt; &quot;Raoul&quot;(3) () -&gt; &#123;return &quot;Mario&quot;;&#125;(4) (Integer i) -&gt; return &quot;Alan&quot; + i;(5) (String s) -&gt; &#123;&quot;IronMan&quot;;&#125;\n答案：只有4和5是无效的Lambda。\n(1) 这个Lambda没有参数，并返回void。它类似于主体为空的方法：public void run() {}。\n(2) 这个Lambda没有参数，并返回String作为表达式。\n(3) 这个Lambda没有参数，并返回String（利用显式返回语句）。\n(4) return是一个控制流语句。要使此Lambda有效，需要使花括号，如下所示：(Integer i) -&gt; {return &quot;Alan&quot; + i;}。\n(5)“Iron Man”是一个表达式，不是一个语句。要使此Lambda有效，你可以去除花括号和分号，如下所示： (String s) -&gt; &quot;Iron Man&quot;。或者如果你喜欢，可以使用显式返回语句，如下所示：(String s)-&gt;{return &quot;IronMan&quot;;}。\n","tags":["Java8","Lambda"],"path":"2019/05/19/Java8-之-Lambda/","external_link":""},{"title":"Java8 时间和日期API","date":"2019-05-03T04:34:29.000Z","content":"旧API的问题：\n在Java 1.0中，对日期和时间的支持只能依赖java.util.Date类。 存在的问题有：\n\n年份的起始选择是1900年\n月份的起始从0开始\n\n在Java 1.1中， Date类中的很多方法被废弃了，取而代之的是java.util.Calendar类 ，仍然有很多问题:\n\n月份依旧是从0开始计算\n同时存在Date和Calendar这两个类，增加了程序员的疑惑\n有的特性只在某一个类有提供，比如DateFormat只在Date类里有\nDateFormat不是线程安全的\nDate和Calendar类都是可变的\n\n\n所有这些缺陷和不一致导致用户们转投第三方的日期和时间库，比如Joda-Time。为了解决这些问题， Oracle决定在原生的Java API中提供高质量的日期和时间支持。所以，你会看到Java 8在java.time包中整合了很多Joda-Time的特性。\n\n先给出几个新API的示例，可以看到，Java8中对时间、日期的操作是非常优雅和易于理解的。\n1234567891011121314151617181920212223LocalDate today = LocalDate.now();  获取两个日期的间隔LocalDate today = LocalDate.now();LocalDate someDay = LocalDate.of(2021, Month.MAY, 14);Period period = Period.between(today, someDay); interval : 2 years, 0 months, 10 days System.out.printf(interval : %d years, %d months, %d days , period.getYears(), period.getMonths(), period.getDays());  取下一天：LocalDate tomorrow = today.plusDays(1); 取本月第1天：LocalDate secondDay = today.withDayOfMonth(1); 取本月最后一天LocalDate lastDay = today.with(TemporalAdjusters.lastDayOfMonth()); 取本月第一个周一LocalDate firstMonday = today.with(TemporalAdjusters.firstInMonth(DayOfWeek.MONDAY)); 获取当前时刻LocalTime now = LocalTime.now(); 将当前时间加上2小时LocalTime then = now.plusHours(2); 获取一个时间段的毫秒数long window = Duration.ofMinutes(45).toMillis();\n时间、日期、时间戳\nLocalDate\n\n该类的实例是一个不可变对象，它只包含日期，并不含时间。另外，它不附带时区信息。\n\n12345678910 创建一个LocalDate对象并读取其值LocalDate date = LocalDate.of(2014, 3, 18);  2014-03-18int year = date.getYear();Month month = date.getMonth();int day = date.getDayOfMonth();  18DayOfWeek dow = date.getDayOfWeek();int len = date.lengthOfMonth();  31boolean leap = date.isLeapYear();  false 是否闰年 你还可以使用工厂方法从系统时钟中获取当前的日期：LocalDate today = LocalDate.now();\nLocalTime\n一天中的时间，比如13:45:20，可以使用LocalTime类表示 :\n1234LocalTime time = LocalTime.of(13, 45, 20);int hour = time.getHour();int minute = time.getMinute();int second = time.getSecond();\nLocalDate和LocalTime都可以通过字符串创建：\n12LocalDate date = LocalDate.parse(2014-03-18);LocalTime time = LocalTime.parse(13:45:20);\nLocalDateTime\nLocalDateTime，是LocalDate和LocalTime的合体。它同时表示了日期和时间，但不带有时区信息，你可以直接创建，也可以通过合并日期和时间对象构造，如下所示。\n1234567891011 直接创建LocalDateTime对象，或者通过合并日期和时间的方式创建 2014-03-18T13:45:20LocalDateTime dt1 = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45, 20);LocalDateTime dt2 = LocalDateTime.of(date, time); 另外，也可以通过它们各自的atTime或者atDate方法，向LocalDate传递一个时间对象，或者向LocalTime传递一个日期对象的方式，创建LocalDateTime对象LocalDateTime dt3 = date.atTime(13, 45, 20);LocalDateTime dt4 = date.atTime(time);LocalDateTime dt5 = time.atDate(date); 从LocalDateTime中提取LocalDate或者LocalTimeLocalDate date1 = dt1.toLocalDate();LocalTime time1 = dt1.toLocalTime();\n时间戳类Instant\n\nUnix元年时间（UTC时区1970年1月1日午夜时分）开始所经历的秒数\n\n1234567891011 静态工厂方法now，它能够帮你获取当前时刻的时间戳Instant.now();*以通过向静态工厂方法ofEpochSecond传递一个代表秒数的值创建一个该类的实例。还有一个增强的重载版本，它接收第二个以纳秒为单位的参数值，对传入作为秒数的参数进行   调整。*Instant.ofEpochSecond(3);Instant.ofEpochSecond(3, 0);Instant.ofEpochSecond(2, 1_000_000_000); 2秒加100万纳秒（1秒）Instant.ofEpochSecond(4, -1_000_000_000); 4秒之前的100万纳秒（1秒）\n可以通过Duration和Period类使用Instant 。\nDuration 、Period\nDuration类主要用于以秒和纳秒衡量时间的长短 。\n1234 获取两个LocalTime对象、两个LocalDateTime对象，或者两个Instant对象之间的durationDuration d1 = Duration.between(time1, time2);Duration d1 = Duration.between(dateTime1, dateTime2);Duration d2 = Duration.between(instant1, instant2);\n\n\n由于LocalDateTime和Instant是为不同的目的而设计的，一个是为了便于人阅读使用，另一个是为了便于机器处理，所以你不能将二者混用。如果你试图在这两类对象之间创建duration，会触发一个DateTimeException异常。\nDuration类主要用于以秒和纳秒衡量时间的长短，所以不能向between方法传递LocalDate对象做参数。\n\n\n使用Period类，得到两个LocalDate之间的时长\n12Period tenDays = Period.between(LocalDate.of(2014, 3, 8),LocalDate.of(2014, 3, 18));\n最后， Duration和Period类都提供了很多非常方便的工厂类，直接创建对应的实例 。\n123456Duration threeMinutes = Duration.ofMinutes(3);Duration threeMinutes = Duration.of(3, ChronoUnit.MINUTES);Period tenDays = Period.ofDays(10);Period threeWeeks = Period.ofWeeks(3);Period twoYearsSixMonthsOneDay = Period.of(2, 6, 1);\n操纵、解析和格式化日期\n截至目前，我们介绍的这些日期时间对象都是不可变的 。\n如果你已经有一个LocalDate对象，想要创建它的一个修改版副本，最直接也最简单的方法是使用withAttribute方法。\n1234LocalDate date1 = LocalDate.of(2014, 3, 18);LocalDate date2 = date1.withYear(2011);LocalDate date3 = date2.withDayOfMonth(25);LocalDate date4 = date3.with(ChronoField.MONTH_OF_YEAR, 9);\n或者以声明的方式操纵LocalDate对象\n1234LocalDate date1 = LocalDate.of(2014, 3, 18);LocalDate date2 = date1.plusWeeks(1);LocalDate date3 = date2.minusYears(3);LocalDate date4 = date3.plus(6, ChronoUnit.MONTHS);\nTemporalAdjuster\n\n有的时候，你需要进行一些更加复杂的操作，比如，将日期调整到下个周日、下个工作日，或者是本月的最后一天。这时，你可以使用重载版本的with方法，向其传递一个提供了更多定制化选择的TemporalAdjuster对象\n\n1234import static java.time.temporal.TemporalAdjusters.*;LocalDate date1 = LocalDate.of(2014, 3, 18);LocalDate date2 = date1.with(nextOrSame(DayOfWeek.SUNDAY));LocalDate date3 = date2.with(lastDayOfMonth());\n另外，还也已创建自定义的TemporalAdjuster，例如获得当前日期的下一个工作日。见《Java 8 in Action》。\n打印输出及解析日期、时间对象\n\n和老的java.util.DateFormat相比较，所有的DateTimeFormatter实例都是线程安全\n的。所以，你能够以单例模式创建格式器实例，就像DateTimeFormatter预定义的那些格式器常量，并能在多个线程间共享这些实例。\n\n1234567891011121314151617181920212223 格式化输出LocalDate date = LocalDate.of(2014, 3, 18);String s1 = date.format(DateTimeFormatter.BASIC_ISO_DATE); 20140318String s2 = date.format(DateTimeFormatter.ISO_LOCAL_DATE); 2014-03-18 解析LocalDate date1 =     LocalDate.parse(20140318,DateTimeFormatter.BASIC_ISO_DATE);LocalDate date2 =     LocalDate.parse(2014-03-18,DateTimeFormatter.ISO_LOCAL_DATE); DateTimeFormatter类还支持一个静态工厂方法，它可以按照某个特定的模式创建格式器DateTimeFormatter formatter =     DateTimeFormatter.ofPattern(ddMMyyyy);LocalDate date1 = LocalDate.of(2014, 3, 18);String formattedDate = date1.format(formatter);LocalDate date2 = LocalDate.parse(formattedDate, formatter); ofPattern方法也提供了一个重载的版本，使用它你可以创建某个Locale的格式器DateTimeFormatter italianFormatter =    DateTimeFormatter.ofPattern(d. MMMM yyyy, Locale.ITALIAN);LocalDate date1 = LocalDate.of(2014, 3, 18);String formattedDate = date.format(italianFormatter);  18. marzo 2014LocalDate date2 = LocalDate.parse(formattedDate, italianFormatter);\n最后，如果你还需要更加细粒度的控制， DateTimeFormatterBuilder类还提供了更复杂\n的格式器，你可以选择恰当的方法，一步一步地构造自己的格式器。另外，它还提供了非常强大的解析功能，比如区分大小写的解析、柔性解析（允许解析器使用启发式的机制去解析输入，不精 确 地 匹 配 指 定 的 模 式 ）、 填 充 ，以及在格式器中指 定可选节 。比 如 ， 你可以通 过DateTimeFormatterBuilder 自己编程实现italianFormatter，代码清单如下。\n12345678DateTimeFormatter italianFormatter = new DateTimeFormatterBuilder()    .appendText(ChronoField.DAY_OF_MONTH)    .appendLiteral(. )    .appendText(ChronoField.MONTH_OF_YEAR)    .appendLiteral( )    .appendText(ChronoField.YEAR)    .parseCaseInsensitive()    .toFormatter(Locale.ITALIAN);\n时区\n\n日期和时间的类都不包含时区信息。\n时区的处理是新版日期和时间API新增加的重要功能，使用新版日期和时间API时区的处理被极大地简化了。新的java.time.ZoneId类是老版java.util.TimeZone的替代品。\n\n可以通过调用ZoneId的getRules()得到指定时区。每个特定的ZoneId对象都由一个地区ID标识，比如：\nZoneId romeZone = ZoneId.of(&quot;EuropeRome);\n地区ID都为“{区域}{城市}”的格式，这些地区集合的设定都由英特网编号分配机构（IANA）的时区数据库提供。\n还可以通过Java 8的新方法toZoneId将一个老的时区对象转换为ZoneId：\nZoneId zoneId = TimeZone.getDefault().toZoneId();\n一旦得到一个ZoneId对象，你就可以将它与LocalDate、 LocalDateTime或者是Instant对象整合起来，构造为一个ZonedDateTime实例，它代表了指定时区的时间点，代码清单如下所示。\n1234567891011121314 为时间点添加时区信息LocalDate date = LocalDate.of(2014, Month.MARCH, 18);ZonedDateTime zdt1 = date.atStartOfDay(romeZone);LocalDateTime dateTime = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45);ZonedDateTime zdt2 = dateTime.atZone(romeZone);Instant instant = Instant.now();ZonedDateTime zdt3 = instant.atZone(romeZone); 通过ZoneId，可以将LocalDateTime转换为Instant：LocalDateTime dateTime = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45);Instant instantFromDateTime = dateTime.toInstant(romeZone); 还可以通过反向的方式得到LocalDateTime对象：Instant instant = Instant.now();LocalDateTime timeFromInstant = LocalDateTime.ofInstant(instant, romeZone);\n","tags":["Java8"],"path":"2019/05/03/Java8-时间和日期API/","external_link":""},{"title":"Java8 之 Stream","date":"2019-06-03T03:40:33.000Z","content":"使用Java8的Stream可以让你的代码：更简洁，更易读；更灵活；可并行\n\n引言\n下面两段代码都是用来返回低热量的菜肴名称 ，一个是用Java 7写的，另一个是用Java 8的流 。\n\nJava7：\n\n123456789101112131415161718 List&lt;Dish&gt; menu = ....List&lt;Dish&gt; lowCaloricDishes = new ArrayList&lt;&gt;(); 筛选出低热量的菜肴for(Dish d: menu)    if(d.getCalories() &lt; 400)        lowCaloricDishes.add(d); 根据热量对菜肴排序Collections.sort(lowCaloricDishes, new Comparator&lt;Dish&gt;() &#123;    public int compare(Dish d1, Dish d2)&#123;    \treturn Integer.compare(d1.getCalories(), d2.getCalories());    &#125;&#125;); 收集排序好的菜肴的名称List&lt;String&gt; lowCaloricDishesName = new ArrayList&lt;&gt;();for(Dish d: lowCaloricDishes)    lowCaloricDishesName.add(d.getName());在这段代码中，你用了一个“垃圾变量” lowCaloricDishes。它唯一的作用就是作为一次性的中间容器\n\nJava8：\n\n1234567 List&lt;Dish&gt; menu = ....List&lt;String&gt; lowCaloricDishesName =    menu.stream() 从List获取流    .filter(d -&gt; d.getCalories() &lt; 400)  筛选出低热量的菜肴    .sorted(comparing(Dish::getCalories)) 根据热量对菜肴排序    .map(Dish::getName) 将每个Dish映射成String    .collect(toList()); 收集排序好的菜肴的名称\n为了利用多核架构并行执行这段代码，你只需要把stream()换成parallelStream()：\n123456List&lt;String&gt; lowCaloricDishesName =    menu.parallelStream() 使用并行流    .filter(d -&gt; d.getCalories() &lt; 400)    .sorted(comparing(Dishes::getCalories))    .map(Dish::getName)    .collect(toList());\n\n代码是以声明性方式写的：说明想要完成什么（筛选热量低的菜肴）而不是说明如何实现（通过if和循环等）。这种方法加上行为参数化让你可以轻松应对变化：你很容易再创建一个代码版本，利用\nLambda表达式来筛选高卡路里的菜肴，而用不着去复制粘贴代码\n可以把几个基础操作链接起来，来表达复杂的数据处理流程，同时保持代码清晰可读 。\n方便的进行并行处理，无需自己实现多线程代码。\n\n外部迭代与内部迭代\n\n使用Collection接口需要用户去做迭代（比如用for-each），这称为外部迭代。 相反，Streams库使用内部迭代——它帮你把迭代做了，还把得到的流值存在了某个地方，你只要给出一个函数说要干什么就可以了。\n\n12345678910111213141516 用for-each循环外部迭代List&lt;String&gt; names = new ArrayList&lt;&gt;();for(Dish d: menu)&#123;\tnames.add(d.getName());&#125; 用背后的迭代器做外部迭代List&lt;String&gt; names = new ArrayList&lt;&gt;();Iterator&lt;String&gt; iterator = menu.iterator();while(iterator.hasNext()) &#123;    Dish d = iterator.next();    names.add(d.getName());&#125;使用流，内部迭代List&lt;String&gt; names = menu.stream()\t.map(Dish::getName)\t.collect(toList());\n让我们用一个比喻来解释内部迭代的差异和好处吧。比方说你和你两岁的女儿索菲亚说，把玩具收起来：\n外部迭代：\n\n你：“索菲亚，我们把玩具收起来吧。地上还有玩具吗？”\n索菲亚：“有，球。”\n你：“好，把球放进盒子里。还有吗？”\n索菲亚：“有，那是我的娃娃。”\n你：“好，把娃娃放进盒子里。还有吗？”\n索菲亚：“有，有我的书。”\n你：“好，把书放进盒子里。还有吗？”\n索菲亚：“没了，没有了。”\n你：“好，我们收好啦。”\n\n这正是你每天都要对Java集合做的。你外部迭代一个集合，显式地取出每个项目再加以处理 。\n而使用内部迭代，只需要说你的意图就好了：\n\n把地上所有的玩具都放进盒子里\n\n内部迭代比较好的原因有二：\n第一，索非亚可以选择一只手拿娃娃，另一只手拿球；第二，她可以决定先拿离盒子最近的那个\n东西，然后再拿别的。\n同样的道理Streams库的内部迭代可以自动选择一种适合你硬件的数据表示和并行实现。与此相反，一旦通过写for-each而选择了外部迭代，那你基本上就要自己管理所有的并行问题了 。\n流操作\njava.util.stream.Stream中的Stream接口定义了许多操作。它们可以分为两大类。 中间操作与终端操作。\n12345List&lt;String&gt; names = menu.stream()    .filter(d -&gt; d.getCalories() &gt; 300) 中间操作    .map(Dish::getName) 中间操作    .limit(3) 中间操作    .collect(toList()); 终端操作\n中间操作\n诸如filter或sorted等中间操作会返回另一个流。这让多个操作可以连接起来形成一个查询。重要的是，除非流水线上触发一个终端操作，否则中间操作不会执行任何处理 。这是因为中间操作一般都可以合并起来，在终端操作时一次性全部处理 。\n12345678910111213141516171819List&lt;Dish&gt; menu = Arrays.asList(            new Dish(pork, false, 800, Dish.Type.MEAT),            new Dish(beef, false, 700, Dish.Type.MEAT),            new Dish(season fruit, true, 120, Dish.Type.OTHER),            new Dish(chicken, false, 400, Dish.Type.MEAT),            new Dish(french fries, true, 530, Dish.Type.OTHER));List&lt;String&gt; names = menu.stream()    .filter(d -&gt; &#123;        System.out.println(filtering + d.getName());        return d.getCalories() &gt; 300;    &#125;)    .map(d -&gt; &#123;        System.out.println(mapping + d.getName());        return d.getName();    &#125;)    .limit(3)    .collect(toList());System.out.println(names);\n打印结果如下：\n12345678filtering porkmapping porkfiltering beefmapping beeffiltering season fruitfiltering chickenmapping chicken[pork, beef, chicken]\n你会发现，有好几种优化利用了流的延迟性质。第一，尽管很多菜的热量都高于300卡路里，但只选出了前三个！这是因为limit操作和一种称为短路的技巧，我们会在后文中解释。第二，尽管filter和map是两个独立的操作，但它们合并到同一次遍历中了（我们把这种技术叫作循环合并）。\n终端操作\n终端操作会从流的流水线生成结果。其结果是任何不是流的值，比如List、 Integer，甚至void。\n123menu.stream().forEach(System.out::println); forEach是一个返回void的终端操作menu.stream().collect(toList());  返回Listmenu.stream().collect(toMap(Dish::getName, Function.identity())); 返回Map\n使用流\n总而言之，流的使用一般包括三件事：\n\n一个数据源（如集合）来执行一个查询；\n一个中间操作链，形成一条流的流水线；\n一个终端操作，执行流水线，并能生成结果。\n\n详细的中间操作和终端操作请参见API文档。\n使用流\nStream API支持的许多操作。这些操作能让你快速完成复杂的数据查询，如筛选、切片、映射、查找、匹配和归约。\n最后，我们会看看一些特殊的流：数值流、来自文件和数组等多种来源的流，最后是无限流 。\n筛选\n\nfilter(Predicate&lt;T&gt;)\n接受一个谓词（一个返回boolean的函数）作为参数，并返回一个包括所有符合谓词的元素的流。\n\n1234 筛选出所有素菜，创建一张素食菜单List&lt;Dish&gt; vegetarianMenu = menu.stream()    .filter(Dish::isVegetarian)    .collect(toList());\n\ndistinct()\n它会返回一个元素各异（根据流所成元素的hashCode和equals方法实现）的流\n\n123456 筛选出列表中所有的偶数，并确保没有重复List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);numbers.stream()    .filter(i -&gt; i % 2 == 0)    .distinct()    .forEach(System.out::println);\n\nlimit(int)\n该方法会返回一个不超过给定长度的流。所需的长度作为参数传递给limit。如果流是有序的，则最多会返回前n个元素。\n\n12345 选出热量超过300卡路里的头三道菜List&lt;Dish&gt; dishes = menu.stream()    .filter(d -&gt; d.getCalories() &gt; 300)    .limit(3)    .collect(toList());\n请注意limit也可以用在无序流上，比如源是一个Set。这种情况下， limit的结果不会以任何顺序排列。\n\nskip(n)\n返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回一个空流。\n\n12345 跳过超过300卡路里的头两道菜，并返回剩下的List&lt;Dish&gt; dishes = menu.stream()    .filter(d -&gt; d.getCalories() &gt; 300)    .skip(2)    .collect(toList());\n映射\n\n一个非常常见的数据处理套路就是从某些对象中选择信息。比如在SQL里，你可以从表中选择一列。 Stream API也通过map和flatMap方法提供了类似的工具。\n\n\nmap (Function&lt;T,R&gt;)\n接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素\n\n1234 方法引用Dish::getName传给了map方法，来提取流中菜肴的名称List&lt;String&gt; dishNames = menu.stream()    .map(Dish::getName)    .collect(toList());\n因为getName方法返回一个String，所以map方法输出的流的类型就是Stream。\n12345提取每个菜肴名称的长度List&lt;Integer&gt; dishNameLengths = menu.stream()    .map(Dish::getName)    .map(String::length)    .collect(toList());\n第一个map将Stream&lt;Dish&gt;映射为Stream&lt;String&gt;，然后第二个map又将Stream&lt;String&gt;映射为Stream&lt;Integer&gt;，在IDEA中可以看到给出的提示，如下图：\n\n\nflatMap(Function&lt;T,R&gt;)\n将函数返回的Stream&lt;T&gt;并不是分别映射成一个流(导致最终映射的结果是Stream&lt;Stream&lt;T&gt;&gt;)，而是映射成流的内容（最终映射结果为Stream&lt;T&gt;）。\n\n对于一张单表，如何返回一张列表，列出里面各不相同的字符呢？\n例如，给定单词列表[&quot;Hello&quot;, &quot;World&quot;]，你想要返回列表[&quot;H&quot;,&quot;e&quot;,&quot;l&quot;,&quot;o&quot;,&quot;W&quot;,&quot;r&quot;,&quot;d&quot;]。\n你可能会认为这很容易，你可以把每个单词映射成一张字符表，然后调用distinct来过滤重复的字符。第一个版本可能是这样的：\n12345List&lt;String&gt; words = Arrays.asList(Hello, World);words.stream()    .map(word -&gt; word.split())    .distinct()    .collect(toList());\n传递给map方法的Lambda为每个单词返回了一个String[]。因此，map返回的流实际上是Stream&lt;String[]&gt;类型的。你真正想要的是用Stream&lt;String&gt;来表示一个字符流。\n\n首先，你需要一个字符流，而不是数组流。有一个叫作Arrays.stream()的方法可以接受一个数组并产生一个流 ：\n12345words.stream()    .map(word -&gt; word.split()) 每个单词转换为由其字母构成的数组    .map(Arrays::stream) 让每个数组变成一个单独的流    .distinct()    .collect(toList());\n当前的解决方案仍然搞不定！ 这是因为，你现在得到的是 Stream&lt;Stream&lt;String&gt;&gt;。\n现在flatMap终于派上用场了：\n12345List&lt;String&gt; uniqueCharacters = words.stream()    .map(w -&gt; w.split())    .flatMap(Arrays::stream)    .distinct()    .collect(Collectors.toList());\n\n上面的代码也可以直接写成：\n1234List&lt;String&gt; uniqueCharacters = words.stream()    .flatMap(w -&gt; Arrays.stream(w.split()))    .distinct()    .collect(toList());\n查找和匹配\n数据集中的某些元素是否匹配一个给定的属性。 Stream通过allMatch、 anyMatch、 noneMatch、 findFirst和findAny方法提供了这样的工具 。\n\nanyMatch(Predicate&lt;T&gt;)\n检查谓词是否至少匹配一个元素\n\n1boolean hasVegetarian = menu.stream().anyMatch(Dish::isVegetarian);\n\nallMatch(Predicate&lt;T&gt;)\n检查谓词是否匹配所有元素\n\n1boolean isHealthy = menu.stream().allMatch(d -&gt; d.getCalories() &lt; 1000);\n\nnoneMatch(Predicate&lt;T&gt;)\n没有任何元素与给定的谓词匹配\n\n查找元素\n\nfindAny(Predicate&lt;T&gt;)\n将返回当前流中的任意元素\n\n123Optional&lt;Dish&gt; dish = menu.stream()    .filter(Dish::isVegetarian)    .findAny();\n流水线将在后台进行优化使其只需走一遍，并在利用短路找到结果时立即结束。\nOptional 是什么？\n\nOptional&lt;T&gt;类（java.util.Optional）是一个容器类，代表一个值存在或不存在。在上面的代码中， findAny可能什么元素都没找到。 Java 8的库设计人员引入了Optional&lt;T&gt;，这样就不用返回众所周知容易出问题的null了。\n\n我们在这里不会详细讨论Optional，以后的文章中会进行介绍。这里只给出几个常见的API。\n\nisPresent()将在Optional包含值的时候返回true, 否则返回false。\nifPresent(Consumer&lt;T&gt; block)会在值存在的时候执行给定的代码块。\nT get()会在值存在时返回值，否则抛出一个NoSuchElement异常。\nT orElse(T other)会在值存在时返回值，否则返回一个默认值\n\n例如，在前面的代码中你需要显式地检查Optional对象中是否存在一道菜可以访问其名称：\n1234menu.stream()    .filter(Dish::isVegetarian)    .findAny() 返回一个Optional&lt;Dish&gt;    .ifPresent(d -&gt; System.out.println(d.getName()); 如果包含一个值就打印它，否则什么都不做\n\nfindFirst (Predicate&lt;T&gt;)\n有些流有一个出现顺序（encounter order）来指定流中项目出现的逻辑顺序（比如由List或排序好的数据列生成的流）。对于这种流，你可能想要找到第一个元素。\n\n12345List&lt;Integer&gt; someNumbers = Arrays.asList(1, 2, 3, 4, 5);Optional&lt;Integer&gt; firstSquareDivisibleByThree = someNumbers.stream()    .map(x -&gt; x * x)    .filter(x -&gt; x % 3 == 0)    .findFirst();  9\n\n何时使用findFirst和findAny你可能会想，为什么会同时有findFirst和findAny呢？答案是并行。找到第一个元素在并行上限制更多。如果你不关心返回的元素是哪个，请使用findAny，因为它在使用并行流时限制较少。\n\n归约\n\nreduce(T identity, BinaryOperator&lt;T&gt; accumulator)\n在流上进行规约操作，接收一个初始值T，和一个BinaryOperator。后者将两个元素结合起来产生一个新值 。\n\n12345678 所有元素的和int sum = numbers.stream().reduce(0, (a, b) -&gt; a + b); 所有元素的积int product = numbers.stream().reduce(1, (a, b) -&gt; a * b); 使用方法引用int sum = numbers.stream().reduce(0, Integer::sum); 使用无初试值的版本，当流中没有值时，Optional中为nullOptional&lt;Integer&gt; sum = numbers.stream().reduce((a, b) -&gt; (a + b));\n求最大值和最小值：\n12Optional&lt;Integer&gt; max = numbers.stream().reduce(Integer::max);Optional&lt;Integer&gt; min = numbers.stream().reduce(Integer::min);\n数值流\n原始类型流特化\n我们在前面看到了可以使用reduce方法计算流中元素的总和。例如，你可以像下面这样计算菜单的热量：\n123int calories = menu.stream()\t.map(Dish::getCalories)\t.reduce(0, Integer::sum);\n这段代码的问题是，它有一个暗含的装箱成本。每个Integer都必须拆箱成一个原始类型，再进行求和。要是可以直接像下面这样调用sum方法，岂不是更好？\n123int calories = menu.stream()\t.map(Dish::getCalories)\t.sum();\n但这是不可能的。问题在于map方法会生成一个Stream&lt;T&gt;。虽然流中的元素是Integer类型，但Stream没有定义sum方法。\nJava 8引入了三个原始类型特化流接口来解决这个问题： IntStream、 DoubleStream和LongStream，分别将流中的元素特化为int、 long和double，从而避免了暗含的装箱成本。每个接口都带来了进行常用数值归约的新方法，比如sum、max。此外还有在必要时再把它们转换回对象流的方法。\n1234 映射到数值流int calories = menu.stream()\t.mapToInt(Dish::getCalories)\t.sum();\n一旦有了数值流，你可能会想把它转换回非特化流。例如，IntStream上的操作只能产生原始整数： IntStream 的 map操作接受的Lambda必须接受int并返回int。但是你可能想要生成另一类值。\n12IntStream intStream = menu.stream().mapToInt(Dish::getCalories);Stream&lt;Integer&gt; stream = intStream.boxed();\n数值范围\n假设你想要生成1和100之间的所 有数字。\nJava 8引入了IntStream和LongStream，帮助生成这种范围。他们都有两个方法range和rangeClosed。这两个方法都是第一个参数接受起始值，第二个参数接受结束值。但range是不包含结束值的，而rangeClosed则包含结束值。\n12生成[1,100]之间的偶数IntStream evenNumbers = IntStream.rangeClosed(1, 100).filter(n -&gt; n % 2 == 0);\n构建流\n由值创建流\n12345 Stream.of创建流Stream&lt;String&gt; stream = Stream.of(Java 8 , Lambdas , In , Action);stream.map(String::toUpperCase).forEach(System.out::println); empty()得到一个空流Stream&lt;String&gt; emptyStream = Stream.empty();\n由数组创建流\n123 Arrays.stream从数组创建一个流int[] numbers = &#123;2, 3, 5, 7, 11, 13&#125;;int sum = Arrays.stream(numbers).sum();\n由文件生成流\nJava中用于处理文件等IO操作的NIO API（非阻塞 IO）已更新，以便利用Stream API。java.nio.file.Files中的很多静态方法都会返回一个流。例如，一个很有用的方法是Files.lines，它会返回一个由指定文件中的各行构成的字符串流。\n123456789 统计一个文件中有多少各不相同的词long uniqueWords = 0;try(Stream&lt;String&gt; lines =     Files.lines(Paths.get(data.txt), Charset.defaultCharset()))&#123;        uniqueWords = lines.flatMap(line -&gt; Arrays.stream(line.split( )))            .distinct()            .count();&#125;catch(IOException e)&#123;&#125;\n由函数生成流：创建无限流\n\n迭代\n\niterate方法接受一个初始值，还有一个依次应用在每个产生的新值上的Lambda\n123Stream.iterate(0, n -&gt; n + 2)    .limit(10)    .forEach(System.out::println);\n请注意，iterate将生成一个无限流——这个流没有结尾，因为值是按需计算的，可以永远计算下去。我们说这个流是无界的。正如我们前面所讨论的，这是流和集合之间的一个关键区别。我们使用limit方法来显式限制流的大小。\n一般来说，在需要依次生成一系列值的时候应该使用iterate 。\n123456Stream.iterate(new int[]&#123;0, 1&#125;,               t -&gt; new int[]&#123;t[1],t[0] + t[1]&#125;)    .limit(10)    .map(t -&gt; t[0])    .forEach(System.out::println);这段代码将打印斐波纳契数列： 0, 1, 1, 2, 3, 5, 8, 13, 21, 34…\n\n生成\n\n与iterate方法类似， generate方法也可让你按需生成一个无限流。但generate不是依次对每个新生成的值应用函数的。它接受一个Supplie&lt;T&gt;类型的Lambda提供新的值 。\n12345678910Stream.generate(Math::random)    .limit(5)    .forEach(System.out::println);*0.94108102941061290.65862707556345920.95928591172668730.137433966594870060.3942776037651241*\n我们使用的供应源（指向Math.random的方法引用）是无状态的：它不会在任何地方记录任何值。但供应源不一定是无状态的。你可以创建存储状态的供应源，它可以修改状态，并在为流生成下一个值时使用。\n123456789101112IntSupplier fib = new IntSupplier()&#123;    private int previous = 0;    private int current = 1;    public int getAsInt()&#123;        int oldPrevious = this.previous;        int nextValue = this.previous + this.current;        this.previous = this.current;        this.current = nextValue;        return oldPrevious;    &#125;&#125;;IntStream.generate(fib).limit(10).forEach(System.out::println);\n收集器\n你有一个由Transaction构成的List，并且想按照名义货币进行分组。在没有Lambda的Java里，哪怕像这种简单的用例实现起来都很啰嗦，就像下面这样。\n12345678910111213 建立累积交易分组的MapMap&lt;Currency, List&lt;Transaction&gt;&gt; transactionsByCurrencies = new HashMap&lt;&gt;();for (Transaction transaction : transactions) &#123;     提取Transaction的货币    Currency currency = transaction.getCurrency();    List&lt;Transaction&gt; transactionsForCurrency = transactionsByCurrencies.get(currency);    if (transactionsForCurrency == null) &#123; 如果分组Map中没有这种货币的条目，就创建一个        transactionsForCurrency = new ArrayList&lt;&gt;();        transactionsByCurrencies.put(currency, transactionsForCurrency);    &#125;     将当前遍历的Transaction加入同一货币的Transaction的List    transactionsForCurrency.add(transaction);&#125;\n尽管代码的目的很简单——把列表中的交易按货币分组——但是写起来却很麻烦。更糟糕的是，读起来比写起来更费劲！\n而用Stream中collect方法，你就可以用一句话实现 ：\n12Map&lt;Currency, List&lt;Transaction&gt;&gt; transactionsByCurrencies =\ttransactions.stream().collect(groupingBy(Transaction::getCurrency));\n收集器简介\n传递给collect()的参数是Collector接口的一个实现 。刚才是通过groupingBy方法获得了一个收集器的实现。我们之前也见过collect(Collectos.toList())的用法，所以显然Collectos.toList()也是返回了Collector接口的一种实现。\n我们先看一些JDK预定义的收集器，它们就可以处理大部分实际情况。\n预定义收集器\n分组\n\nCollectors.groupingBy(Function&lt;T,K&gt;)\n接收一个分类函数，返回一个收集器。该收集器能根据分组函数对流中的元素进行分组，收集到一个Map&lt;K,List&lt;T&gt;&gt;。\n\n1234Map&lt;Dish.Type, List&lt;Dish&gt;&gt; dishesByType =\tmenu.stream().collect(groupingBy(Dish::getType));System.out.println(dishesByType); &#123;OTHER=[season fruit, french fries, rice, pizza], MEAT=[pork, beef, chicken], FISH=[prawns, salmon]&#125;\n上面的代码中，分类函数是提取每个DIsh的Type。分类函数还可以做的更复杂，而不仅是属性提取。\n12345678910public enum CaloricLevel &#123; DIET, NORMAL, FAT &#125;Map&lt;CaloricLevel, List&lt;Dish&gt;&gt; dishesByCaloricLevel = menu.stream()    .collect(        groupingBy(dish -&gt; &#123;            if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET;            else if (dish.getCalories() &lt;= 700) return                CaloricLevel.NORMAL;            else return CaloricLevel.FAT;        &#125;)    );\n上面的分类函数根据热量进行分组。可以看到，因为分类函数返回的是CaloricLevel类型，所以最终的Map的键的类型就是CaloricLevel。\n多级分组\n1234567891011121314151617Map&lt;Dish.Type, Map&lt;CaloricLevel, List&lt;Dish&gt;&gt;&gt; dishesByTypeCaloricLevel =    menu.stream().collect(        groupingBy(Dish::getType,                   groupingBy(dish -&gt; &#123;                       if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET;                       else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL;                       else return CaloricLevel.FAT;                   &#125;)                  )\t);System.out.println(dishesByTypeCaloricLevel);*OTHER=&#123;DIET=[season fruit, rice], NORMAL=[french fries, pizza]&#125;, MEAT=&#123;DIET=[chicken], FAT=[pork], NORMAL=[beef]&#125;, FISH=&#123;DIET=[prawns], NORMAL=[salmon]&#125;&#125;*\n按子组收集数据\n观察一下，在多级分组中，外层的groupingBy方法接收了两个参数，第一个参数是外层分类函数，第二个参数实际上是一个Collector。所以第二个参数实际可以传入任意的收集器而不一定是groupingBy()返回的收集器。\n12345678910111213141516 分别统计每种菜肴的个数Map&lt;Dish.Type, Long&gt; typesCount = menu.stream()    .collect(  groupingBy(Dish::getType, counting())  ); &#123;MEAT=3, FISH=2, OTHER=4&#125; 分别统计每种菜肴的卡路里总数Map&lt;Dish.Type, Integer&gt; totalCaloriesByType =menu.stream()    .collect(   groupingBy(Dish::getType, summingInt(Dish::getCalories))    ); 分别统计每种菜肴中，卡路里最高的菜肴Map&lt;Dish.Type, Optional&lt;Dish&gt;&gt; mostCaloricByType = menu.stream().collect(    groupingBy(Dish::getType,               maxBy(comparingInt(Dish::getCalories)))); &#123;FISH=Optional[salmon], OTHER=Optional[pizza], MEAT=Optional[pork]&#125;\n实际上，普通的单参数groupingBy(f)（其中f是分类函数）是groupingBy(f, toList())的简便写法 。\n\n把收集器的结果转换为另一种类型 :\n\n注意到上面的例子中，分组后取卡路里最高的菜肴。最后的结果是Map&lt;Dish.Type, Optional&lt;Dish&gt;&gt;，Map的value是Option&lt;Dish&gt;类型的，你可能想把它转换成Dish类型\n123456789Map&lt;Dish.Type, Dish&gt; mostCaloricByType = menu.stream()    .collect(        groupingBy(Dish::getType,                   collectingAndThen(                       maxBy(comparingInt(Dish::getCalories)),                       Optional::get)                  )    ); &#123;FISH=salmon, OTHER=pizza, MEAT=pork&#125;\n\nCollectors.collectingAndThen()\n这个工厂方法接受两个参数——要转换的收集器以及转换函数，并返回另一个新收集器。新收集器相当于旧收集器的一个包装，使得collect操作的最后一步就是将返回值用转换函数做一个映射。\n\n上面的例子中，被包起来的收集器就是用maxBy建立的那个，而转换函数Optional::get则把返回的Optional中的值提取出来。\n\n与groupingBy联合使用的其他收集器的例子 :\n\n之前讲过，groupingBy方法的第二个参数可以是任意的收集器。再举个复杂点的例子。我们希望将菜单根据Type分组，然后分别统计每个组中都有那些CaloricLevel 。就是说，我们希望的得到如下的分组结果：\n1&#123;OTHER=[DIET, NORMAL], MEAT=[DIET, NORMAL, FAT], FISH=[DIET, NORMAL]&#125;\n这样，如果你想吃鱼并且在减肥，那很容易找到一道菜 。\n看下代码是如何实现的：\n123456789101112Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream()    .collect(        groupingBy(Dish::getType,                    mapping(this::judgeCaloricLevel, toSet())                  )\t);private CaloricLevel judgeCaloricLevel(Dish dish)&#123;    if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET;    else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL;    else return CaloricLevel.FAT; &#125;\n传递给mapping方法的转换函数将Dish映射成了CaloricLevel：生成的CaloricLevel流传递给一个toSet收集器，它和toList类似，不过是把流中的元素累积到Set而不是List中，以便仅保留不相同的值。\n请注意在上示例中，对于返回的Set是什么类型并没有任何保证。但通过使用toCollection，你就可\n以有更多的控制。例如，你可以给它传递一个构造函数引用来要求HashSet：\n123456Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream()    .collect(        groupingBy(Dish::getType,                    mapping(this::judgeCaloricLevel, toCollection(HashSet::new))                  )\t);\n分区\n分区是分组的特殊情况：由一个谓词（返回一个布尔值的函数）作为分类函数，它称分区函数。分区函数返回一个布尔值，这意味着得到的分组Map的键类型是Boolean，于是它最多可以分为两组——true是一组， false是一组。\n12345678 把菜单按照素食和非素食分开Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionedMenu =\tmenu.stream().collect(partitioningBy(Dish::isVegetarian)); &#123;false=[pork, beef, chicken, prawns, salmon],true=[french fries, rice, season fruit, pizza]&#125; 那么通过Map中键为true的值，就可以找出所有的素食菜肴了：List&lt;Dish&gt; vegetarianDishes = partitionedMenu.get(true); 请注意，用同样的分区谓词，对菜单流作筛选，也可以获得相同的结果：List&lt;Dish&gt; vegetarianDishes = menu.stream().filter(Dish::isVegetarian).collect(toList());\n自定义收集器\n我们已经看过JDK中预定义了Collector接口的许多收集器实现，例如通过工厂方法Collectors.toList()或Collectors.groupingBy()获得的预定义收集器。另外，我们也可以为Collector接口提供自己的实现。\n而在学习自定义收集器前，我们先看下collect方法的其他使用方式。\n在之前的代码中，比如menu.stream().filter(Dish::isVegetarian).collect(toList());，我们直接向collect方法传递了一个收集器，然后collect方法就可以拿着这个收集器进行收集工作了。在这里，collect方法拿着toList()提供的收集器，将上游流中的每个元素收集到一个List中。\n然而，collect方法还有其它重写版本：\n123456List&lt;Dish&gt; vegetarianDishs =     menu.stream()        .filter(Dish::isVegetarian)        .collect(ArrayList::new,                (list, dish) -&gt; list.add(dish),                (list1, list2) -&gt; list1.addAll(list2));\n看下collect该重写版本的定义：\n123&lt;R&gt; R collect(Supplier&lt;R&gt; supplier,              BiConsumer&lt;R, ? super T&gt; accumulator,              BiConsumer&lt;R, R&gt; combiner);\n\nsupplier : 该函数定义如何获得一个用于保存最终元素的容器。\naccumulator：该函数定义如何将流中的元素追加到结果容器\ncombiner: 该函数定义如何将两个部分结果容器，合并为一个结果容器\ncollect函数最终返回一个结果容器。\n\n在使用串行流的情况下，该collect方法执行的步骤类似于：\n1234R result = supplier.get(); 从supplier函数获得一个用于保存最终元素的容器。for (T element : this stream)\taccumulator.accept(result, element); accumulator函数式接口中会将元素追加到结果容器return result;\n注意到上面只调用了一次supplier函数，并且没有使用到combiner，这是应为如果在串行流中收集，只会生成一个结果容器。但是如果使用并行流时，会调用多次supplier来获得多个部分结果容器，然后combiner函数会将这些部分结果容器最终组合到一起。\n可以通过例子来看下：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172List&lt;Dish&gt; vegetarianDishes =                menu.parallelStream()                    .filter(Dish::isVegetarian)                    .collect(() -&gt; &#123;                                 synchronized (CollectorTest.class) &#123;                                     System.out.println(create new list);                                     return new ArrayList&lt;&gt;();                                 &#125;                             &#125;*supplier*,                             (list, dish) -&gt; &#123;                                 synchronized (CollectorTest.class) &#123;                                     System.out.println(add dish:  + dish);                                     list.add(dish);                                 &#125;                             &#125;*accumulator*,                             (list1, list2) -&gt; &#123;                                 synchronized (CollectorTest.class) &#123;                                     System.out.println(combine list);                                     System.out.println(list1:  + list1);                                     System.out.println(list2:  + list2);                                     list1.addAll(list2);                                     System.out.println(after combine:  + list1);                                 &#125;                             &#125;*combiner*);*加上synchronized是为了防止多线程会并发调用supplier、accumulator、combiner，打印的时候发生混乱。控制台输出如下（倒着看更容易观察清楚。。）：create new listcreate new listcreate new listadd dish: ricecreate new listadd dish: season fruitcreate new listcombine listlist1: []list2: []after combine: []create new listcreate new listadd dish: pizzacreate new listcreate new listcombine listlist1: []list2: []after combine: []combine listlist1: [season fruit]list2: []after combine: [season fruit]combine listlist1: []list2: [season fruit]after combine: [season fruit]add dish: french friescombine listlist1: [pizza]list2: []after combine: [pizza]combine listlist1: [french fries]list2: [rice]after combine: [french fries, rice]combine listlist1: [french fries, rice]list2: [pizza]after combine: [french fries, rice, pizza]combine listlist1: [season fruit]list2: [french fries, rice, pizza]after combine: [season fruit, french fries, rice, pizza]*\n可以看到，创建了不只两个中间结果容器，然后最终他们都被合并到一个结果容器中。至于到底会创建几个中间结果容器(即同时创建的子任务个数)，与子任务的大小和CPU核心线程数有关。具体内容可参考《Java8实战》关于Spliterator和ForkJoinPool相关部分。\n理解 Collector 接口声明的方法\n理解了上面的内容，在来看Collector就容易的多了。\n之前说过，toList()返回了一个预定义的收集器实现，当我们调用stream.collect(toList())时，collect方法会使用该收集器，将流中的所有元素收集成一个List。我们通过研究这个收集器是怎么实现的，可以很好地了解：\n\nCollector接口是怎么定义的\n收集器被传入到collect()方法后，是如何被使用的。\n\n先看下Collector接口的定义。\n123456789101112*    T是流中要收集的项目的泛型。    A是累加器本身的类型。累加器在收集过程中用于累积部分结果。    R是收集操作得到的对象的类型。（通常但并不一定是集合）*public interface Collector&lt;T, A, R&gt; &#123;    Supplier&lt;A&gt; supplier();    BiConsumer&lt;A, T&gt; accumulator();    Function&lt;A, R&gt; finisher();    BinaryOperator&lt;A&gt; combiner();    Set&lt;Characteristics&gt; characteristics();&#125;\n例如，你可以实现一个ToListCollector&lt;T&gt;类，将Stream&lt;T&gt;中的所有元素收集到一个List&lt;T&gt;里：\n1234public class ToListCollector&lt;T&gt; implements Collector&lt;T, List&lt;T&gt;, List&lt;T&gt;&gt;  T 对应 T List&lt;T&gt; 对应A List&lt;T&gt; 对应R\n下面我们来看Collector接口中每个方法的作用。\n\nSupplier&lt;A&gt; supplier()\n在调用时它会创建一个空的累加器实例，供数据收集过程使用。\n\n在我们的ToListCollector中， supplier返回一个空的List，如下所示：\n123public Supplier&lt;List&lt;T&gt;&gt; supplier() &#123;\treturn () -&gt; new ArrayList&lt;T&gt;();&#125;\n你也可以只传递一个构造函数引用：\n123public Supplier&lt;List&lt;T&gt;&gt; supplier() &#123;\treturn ArrayList::new;&#125;\n\nBiConsumer&lt;A, T&gt; accumulator();\naccumulator方法会返回执行归约操作的函数。当遍历到流中第n个元素时，这个函数执行时会有两个参数：保存归约结果的累加器（已收集了流中的前 n - 1 个项目）， 还有第n个元素本身。\n\n对于ToListCollector而言：\n123public BiConsumer&lt;List&lt;T&gt;, T&gt; accumulator() &#123;\treturn List::add;&#125;\n\nFunction&lt;A, R&gt; finisher();\n方法返回在累积过程的最后要调用的一个函数，该函数将累加器对象转换为整个集合操作的最终结果\n\n通常，就像ToListCollector的情况一样，累加器对象恰好符合预期的最终结果，因此无需进行转换。所以finisher方法只需返回identity函数：\n123public Function&lt;List&lt;T&gt;, List&lt;T&gt;&gt; finisher() &#123;\treturn Function.identity();&#125;\n对于顺序流的处理过程，理解supplier、accumulator和finisher三个函数就够了：\n\n对于并行流而言，由于会将流分割成几个子任务并发收集，所以同时会存在多个收集重启，所以最终需要使用combiner函数将这些部分结果容器合并成一个最终的结果容器。\n\nBinaryOperator&lt;A&gt; combiner();\n方法会返回一个供归约操作使用的函数，它定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器要如何合并。\n\n对于toList而言，这个方法的实现非常简单，只要把从流的第二个部分收集到的项目列表加到遍历第一部分时得到\n的列表后面就行了：\n1234public BinaryOperator&lt;List&lt;T&gt;&gt; combiner() &#123;    return (list1, list2) -&gt;     \t\t\t&#123;list1.addAll(list2);return list1; &#125;&#125;\n\nSet&lt;Characteristics&gt; characteristics()\n： 会返回一个不可变的Characteristics集合，提供了一系列特征，也就是一个提示列表，告诉collect方法在执行归约操作的时候可以应用哪些优化（比如并行化）。\nCharacteristics是一个包含三个项目的枚举：\n\nUNORDERED——收集后的顺序可不保持流中元素的“遭遇顺序”(encounter-order)\nCONCURRENT——accumulator函数可以从多个线程同时调用，即收集容器是线程安全的，如果收集器是CONCURRENT，则Supplier只会被调用一次，即自始至终只会创建一个收集容器。如果收集器没有标为UNORDERED，那它仅在用于无序数据源时才可以并发收集。（如果为UNORDERED，则对于有序无序源都进行并发收集）\nIDENTITY_FINISH——这表明完成器方法返回的函数是一个恒等函数，可以跳过。这种情况下，累加器对象将会直接用作归约过程的最终结果。这也意味着，将累加器A不加检查地转换为结果R是安全的。\n\n\n我们迄今开发的ToListCollector是IDENTITY_FINISH的，因为用来累积流中元素的 List已经是我们要的最终结果，用不着进一步转换了，但它并不是UNORDERED，因为用在有序流上的时候，我们还是希望顺序能够保留在得到的List中。最后，它是CONCURRENT的，但我们刚才说过了，仅仅在背后的数据源无序时才会并行处理。\n\n笔者注：《Java8实战》中以上论述有误，ToListCollector不能是CONCURRENT的，因为采用的收集容器ArrayList是非线程安全的，经过我的测试，并行流收集时会发生问题。\n12345678910111213141516171819202122232425262728293031public class ToListCollector&lt;T&gt; implements Collector&lt;T, List&lt;T&gt;, List&lt;T&gt;&gt; &#123;    @Override    public Supplier&lt;List&lt;T&gt;&gt; supplier() &#123;        return ArrayList::new;    &#125;    @Override    public BiConsumer&lt;List&lt;T&gt;, T&gt; accumulator() &#123;        return List::add;    &#125;    @Override    public Function&lt;List&lt;T&gt;, List&lt;T&gt;&gt; finisher() &#123;        return Function.identity();    &#125;    @Override    public BinaryOperator&lt;List&lt;T&gt;&gt; combiner() &#123;        return (list1, list2) -&gt; &#123;            list1.addAll(list2);            return list1;        &#125;;    &#125;    @Override    public Set&lt;Characteristics&gt; characteristics() &#123;        return Collections.unmodifiableSet(EnumSet.of(                IDENTITY_FINISH, CONCURRENT));    &#125;&#125; 使用自定义的收集器。Stream&lt;Integer&gt; integerStream = IntStream.range(1, 1000).mapToObj(Integer::new);List&lt;Integer&gt; collect = integerStream.parallel().collect(new ToListCollector&lt;&gt;());\n并行流\n关于并行流，希望大家还是多看写书和文档，笔者目前也没有理解透彻。。。\n总之，就是在使用并行流时要谨慎。往往你对并行流的理解并不是对的。比如如下两个例子的输出结果，大多数人的判断都是错的：\n1234Stream&lt;Integer&gt; integerStream = Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)；integerStream.parallel().forEach(System.out::println);integerStream.parallel().collect(toList()).forEach(System.out::println);\n如果你感到很奇怪，可以参考我的博客文章Java8 ParallelStream并行流不一定返回乱序结果。\n不过如果不依赖于顺序性时，一般都可放心大胆使用。\n但是并不是使用了并行流后效率就一定高：要考虑到并行化的额外开销。对于较小的数据量，选择并行流几乎从来都不是一个好的决定 。\n另外在这些的情景下，不要使用并行流，原因可以参考《Java8实战》关于并行流的部分：\n\n收集容器是LinkedList时，不要使用并行流\n流是从Stream.iterate()生成时，不要使用并行流\nfindFirst等依赖于元素顺序的操作，不要使用并行流\n\n注意\n流只能遍历一次\n遍历完之后，我们就说这个流已经被消费掉了。可以从原始数据源那里再获得一个新的流来重新遍历一遍（如果数据源是可重放的话，比如集合），但不能对同一个流遍历两遍。\n12345例如，以下代码会抛出一个异常List&lt;String&gt; title = Arrays.asList(Java8, In, Action);Stream&lt;String&gt; s = title.stream();s.forEach(System.out::println);s.forEach(System.out::println); java.lang.IllegalStateException:流已被操作或关闭\n解决方案：《Java8实战》附录：StreamForker 。\n流与集合的区别\n\n\n比如说存在DVD里的电影，DVD就是一个集合，因为它包含了所有的数据。\n现在再来想想在网上通过视频流看电影。流媒体视频播放器只要下载用户观看位置的那几帧就可以了，这样不用等到流中大部分值计算出来，你就可以边下载边播放流（比如观看直播足球赛）。\n\n\n\n\n粗略地说，集合与流之间的差异就在于什么时候进行计算。集合是一个内存中的数据结构，它包含数据结构中目前所有的值——集合中的每个元素都得先算出来才能添加到集合中。（你可以往集合里加东西或者删东西，但是不管什么时候，集合中的每个元素都是放在内存里的，元素都得先算出来才能成为集合的一部分。）\n相比之下，流则是在概念上固定的数据结构（你不能添加或删除元素），其元素则是按需计算的 。流就\n像是一个延迟创建的集合：只有在消费者要求的时候才会计算值 。\n\n\n收集器与规约的关系\ntodo。。。\n总结\n总结一下， Java 8中的Stream API可以让你写出这样的代码：\n\n声明性——更简洁，更易读\n可复合——更灵活\n可并行——性能更好\n\n\n\n\n\nUNO，UNC\nUNO，C\nO，UNC\nO，C\n\n\n\n\nunP,unO\nsup：1，com：0，有序\nsup：1，com：0，有序\nsup：1，com：0，有序\nsup：1，com：0，有序\n\n\nunP,O\nsup：1，com：0，有序\nsup：1，com：0，有序\nsup：1，com：0，有序\nsup：1，com：0，有序\n\n\nP,unO\nsup：n，com：m，有序(并行计算、并行收集)\nsup：1，com：0，无序（并行计算、并发收集）\nsup：n，com：m,有序(并行计算、并行收集)\nsup：1，com：0，无序（并行计算、并发收集）\n\n\nP,O\nsup：n，com：m，有序(并行计算、并行收集)\nsup：1，com：0，无序（并行计算、并发收集）\nsup：n，com：m,有序(并行计算、并行收集)\nsup：n，com：m,有序  (如果Collect是有序的，仅当源为无序时，才并发收集)。此处为并行计算、并行收集。但是收集器会保证收集顺序保持为遭遇顺序。\n\n\n\n\nIf the stream is sequential, it will be sequential.\nIf the stream is parallel, it will be a parallel or concurrent collect. If at least either, the stream or the collector, is unordered and the collector has the CONCURRENT characteristic. it will be concurrent, otherwise it will be parallel.\nhttps:stackoverflow.comquestions50625544confusion-about-characteristics-unordered-in-java-8-in-action-book\n\n","tags":["Java8","Stream"],"path":"2019/06/03/Java8-之-Stream/","external_link":""},{"title":"Spring Boot Actuator","date":"2019-06-19T06:01:57.000Z","content":"Spring Boot Actuator可以帮助你监控和管理Spring Boot应用，比如健康检查、审计、统计和HTTP追踪等。所有的这些特性可以通过JMX或者HTTP endpoints来获得。\nActuator同时还可以与外部应用监控系统整合，比如 Prometheus, Graphite, DataDog, Influx, Wavefront, New Relic等。这些系统提供了非常好的仪表盘、图标、分析和告警等功能，使得你可以通过统一的接口轻松的监控和管理你的应用。\nActuator在Spring Boot 1 和 Spring Boot 2中有所不同。本文使用Spring Boot 2.1.5.RELEASE。\n\n引言-从Spring Boot Admin说起\n在详细讲解Spring Boot Actuator之前，我们先看下Spring Boot Admin，我们用它来做个引子，关于Spring Boot Admin的详细功能介绍，可以另行参考。\nSpring Boot Admin 用于监控基于 Spring Boot 的应用，它是在 Spring Boot Actuator 的基础上提供简洁的可视化 WEB UI。\nSpring Boot Admin 提供了很多功能，如显示 name、id 和 version，显示在线状态，Loggers 的日志级别管理，Threads 线程管理，Environment 管理等。\n创建Spring Boot Admin服务端\n使用Spring Initializr创建：\n\n创建后的pom.xml关键部分如下，其实就只是加入了spring-boot-admin-starter-server依赖:\n1234567891011121314151617181920212223&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;artifactId&gt;    &lt;version&gt;2.1.5.RELEASE&lt;version&gt;    &lt;relativePath&gt; &lt;!-- lookup parent from repository --&gt;&lt;parent&gt;  &lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;de.codecentric&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-admin-starter-server&lt;artifactId&gt;    &lt;dependency&gt;&lt;dependencies&gt;&lt;dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;de.codecentric&lt;groupId&gt;            &lt;artifactId&gt;spring-boot-admin-dependencies&lt;artifactId&gt;            &lt;version&gt;$&#123;spring-boot-admin.version&#125;&lt;version&gt;            &lt;type&gt;pom&lt;type&gt;            &lt;scope&gt;import&lt;scope&gt;        &lt;dependency&gt;    &lt;dependencies&gt;&lt;dependencyManagement&gt;\n在application.yml中配置server.port=8888，让它运行在8888端口\n在运行主类上使用@EnableAdminServer\n1234567@SpringBootApplication@EnableAdminServerpublic class LearnSpringBootAdminApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(LearnSpringBootAdminApplication.class, args);    &#125;&#125;\n运行该应用，访问localhost:8888\n\nSpring Boot Admin已经正常启动，下面我们启动一个应用，并在Admin上进行监控、管理。\n将应用注册到Spring Boot Admin\n可以直接在已有项目中直接引入spring-boot-admin-starter-client依赖。\n我们这里直接创建一个新的项目，还是推荐使用Spring Initializr：\n\n创建后的pom.xml关键部分如下：\n1234567891011121314151617181920212223242526272829&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;artifactId&gt;    &lt;version&gt;2.1.6.RELEASE&lt;version&gt;    &lt;relativePath&gt; &lt;!-- lookup parent from repository --&gt;&lt;parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;de.codecentric&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-admin-starter-client&lt;artifactId&gt;    &lt;dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;artifactId&gt;    &lt;dependency&gt;&lt;dependencies&gt;&lt;dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;de.codecentric&lt;groupId&gt;            &lt;artifactId&gt;spring-boot-admin-dependencies&lt;artifactId&gt;            &lt;version&gt;$&#123;spring-boot-admin.version&#125;&lt;version&gt;            &lt;type&gt;pom&lt;type&gt;            &lt;scope&gt;import&lt;scope&gt;        &lt;dependency&gt;    &lt;dependencies&gt;&lt;dependencyManagement&gt;\napplication.yml中指定Admin服务器的地址，和本服务的运行端口(8000)、服务名\n123spring.boot.admin.client.url: http:localhost:8888server.port: 8000spring.application.name: GreetingServer\n\n点击该应用，进入该应用的监控界面。\n\n什么监控信息都看不到！\n接下来，就需要使用Spring Boot Actuator暴露指标信息，供Spring Boot Admin使用。\n修改GreetingServer应用的application.yml：\n1234567spring.boot.admin.client.url: http:localhost:8888server.port: 8000spring.application.name: GreetingServer# 暴露所有actuator端点management.endpoints.web.exposure.include: *# 暴露服务健康自检的详细信息management.endpoint.health.show-details: always\n重启GreetingServer应用，再次进入Spring Boot Admin：\n\n可以查看JVM、系统变量、Bean、HTTP连接等等监控，还可以通过JMX对运行时的配置进行修改。\n\n显然，是Spring Boot Actuator提供了服务监控、管理等强大功能。下面，进入Actuator的详细介绍吧。\nSpring Boot Actuator\nSpring Boot Actuator可以帮助你监控和管理Spring Boot应用，比如健康检查、审计、统计和HTTP追踪等。所有的这些特性可以通过JMX或者HTTP endpoints来获得。\n除了上面引言中的Spring Boot Admin，还可以与其他更加强大的应用监控系统整合，比如 Prometheus, Graphite, DataDog, Influx, Wavefront, New Relic等。这些系统提供了非常好的仪表盘、图标、分析和告警等功能，使得你可以通过统一的接口轻松的监控和管理你的应用。\n引言中的GreetingServer应用，由于pom依赖了spring-boot-admin-starter-client，从而间接依赖了Actuator。现在我们抛开Spring Boot Admin，只讨论Actuator，所以将pom修改如下：\n12345678910111213141516&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;artifactId&gt;    &lt;version&gt;2.1.5.RELEASE&lt;version&gt;    &lt;relativePath&gt; &lt;!-- lookup parent from repository --&gt;&lt;parent&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;artifactId&gt;    &lt;dependency&gt;    &lt;dependency&gt;&lt;!-- 加入actuator依赖 --&gt;        &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;artifactId&gt;    &lt;dependency&gt;&lt;dependencies&gt;\napplication.yml不变，启动应用，访问localhost:8000actuator，展示了当前Actuator暴露的endpoint，由于在yml中配置了management.endpoints.web.exposure.include: &quot;*&quot;，所以当前可以访问所有endpoint。\n\n比如访问health终端：\n\nhealth终端显示了健康自检的详细情况，这是因为yml中配置了management.endpoint.health.show-details: always，该值默认为never，那么就不会展示每个HealthIndicator的详情，而只说明整个服务是否可用的最终结论。如{�status�:�DOWN�}。\n在“detials”中，有一个名字为&quot;my&quot;的HealthIndicator，这是因为我实现了一个名为MyHealthIndicator自定义的HealthIndicator。\n123456789101112131415@Componentpublic class MyHealthIndicator implements HealthIndicator &#123;    public static int DB_ERROR = 1001;    @Override    public Health health() &#123;        if (GreetingController.canVisitDb) &#123;            成功连接数据库，返回 UP            return new Health.Builder(Status.UP).build();        &#125; else &#123;            连接数据库失败，返回 out of service            return Health.down().withDetail(连接数据库失败, DB_ERROR).build();        &#125;    &#125;&#125;\n关于服务健康自检，可以参考我的《Spring-Cloud-Eureka》服务健康自检一节\nActuator的health端点、和其他所有暴露的端点(endpoint)的信息都可以被其他监控服务所拉取，比如引言中的Spring Boot Admin。\n\n下面的表格展示了Actuator的所有预定义endpoint\n\n\n\nID\n描述\n默认启用\n\n\n\n\nauditevents\n显示当前应用程序的审计事件信息\nYes\n\n\nbeans\n显示一个应用中所有Spring Beans的完整列表\nYes\n\n\nconditions\n显示配置类和自动配置类(configuration and auto-configuration classes)的状态及它们被应用或未被应用的原因\nYes\n\n\nconfigprops\n显示一个所有@ConfigurationProperties的集合列表\nYes\n\n\nenv\n显示来自Spring的 ConfigurableEnvironment的属性\nYes\n\n\nflyway\n显示数据库迁移路径，如果有的话\nYes\n\n\nhealth\n显示应用的健康信息（当使用一个未认证连接访问时显示一个简单的’status’，使用认证连接访问则显示全部信息详情）\nYes\n\n\ninfo\n显示任意的应用信息\nYes\n\n\nliquibase\n展示任何Liquibase数据库迁移路径，如果有的话\nYes\n\n\nmetrics\n展示当前应用的metrics信息\nYes\n\n\nmappings\n显示一个所有@RequestMapping路径的集合列表\nYes\n\n\nscheduledtasks\n显示应用程序中的计划任务\nYes\n\n\nsessions\n允许从Spring会话支持的会话存储中检索和删除(retrieval and deletion)用户会话。使用Spring Session对反应性Web应用程序的支持时不可用。\nYes\n\n\nshutdown\n允许应用以优雅的方式关闭（默认情况下不启用）\nNo\n\n\nthreaddump\n执行一个线程dump\nYes\n\n\n\n如果使用web应用(Spring MVC, Spring WebFlux, 或者 Jersey)，你还可以使用以下端点：\n\n\n\nID\n描述\n默认启用\n\n\n\n\nheapdump\n返回一个GZip压缩的hprof堆dump文件\nYes\n\n\njolokia\n通过HTTP暴露JMX beans（当Jolokia在类路径上时，WebFlux不可用）\nYes\n\n\nlogfile\n返回日志文件内容（如果设置了logging.file或logging.path属性的话），支持使用HTTP Range头接收日志文件内容的部分信息\nYes\n\n\nprometheus\n以可以被Prometheus服务器抓取的格式显示metrics信息\nYes\n\n\n\nMetrics端点\nSpring Boot 2.0中，内部指标的统计使用 Micrometer，我们可以从actuatormetrics获得都有那些指标：\n123456789&#123;  names: [    jvm.gc.pause,    jvm.buffer.memory.used,    jvm.memory.used,    jvm.buffer.count,     ...  ]&#125;\n要获得特定metric的实际值，比如jvm.gc.pause，可以访问actuatormetricsjvm.gc.pause\n123456789101112131415161718192021222324&#123;  name: jvm.gc.pause,  measurements: [    &#123;statistic: Count,value: 3.0&#125;,    &#123;statistic: TotalTime,value: 7.9E7&#125;,    &#123;statistic: Max,value: 7.9E7&#125;  ],  availableTags: [    &#123;      tag: cause,      values: [        Metadata GC Threshold,        Allocation Failure      ]    &#125;,    &#123;      tag: action,      values: [        end of minor GC,        end of major GC      ]    &#125;  ]&#125;\n加入一个Controller：\n123456789@RestControllerpublic class GreetingController &#123;    @GetMapping(greeting1)    public String greeting1() &#123;        return greeting1;    &#125;    @GetMapping(greeting2)    public String greeting2() &#123;        return greeting2;    &#125;&#125;\n启动应用后多访问几次greeting1和greeting2。然后访问actuatormetricshttp.server.requests\n12345678910111213141516171819202122232425&#123;  name: http.server.requests,  description: null,  baseUnit: seconds,  measurements: [      &#123;statistic: COUNT,value: 45&#125;,      &#123;statistic: TOTAL_TIME,value: 1.3034331529999998&#125;,      &#123;statistic: MAX,value: 0.018845546&#125;  ],  availableTags: [      &#123;tag: exception,values: [None]&#125;,      &#123;tag: method,values: [GET]&#125;,      &#123;tag: uri,values: [          actuatormetrics&#123;requiredMetricName&#125;,          greeting1,          actuatorprometheus,          actuatormetrics,          greeting2,          **        ]      &#125;,      &#123;tag: outcome,values: [CLIENT_ERROR,SUCCESS]&#125;,      &#123;tag: status,values: [404,200]&#125;  ]&#125;\n可以看到，一共有45次请求，请求总共时间为1.3034331529999998秒等等统计信息。\n我们还可以根据tag进行下钻（drill down）查询：actuatormetricshttp.server.requests?tag=uri:greeting1\n12345678910111213141516&#123;  name: http.server.requests,  description: null,  baseUnit: seconds,  measurements: [      &#123;statistic: COUNT,value: 1&#125;,      &#123;statistic: TOTAL_TIME,value: 0.007784208&#125;,      &#123;statistic: MAX,value: 0&#125;  ],  availableTags: [      &#123;tag: exception,values: [None]&#125;,      &#123;tag: method,values: [GET]&#125;,      &#123;tag: outcome,values: [SUCCESS]&#125;,      &#123;tag: status,values: [200]&#125;  ]&#125;\n另外可以配置info端点的内容、自定义端点、对端点进行访问控制等，详情可以参考SpringBoot官方文档。\n另外可以配置info端点的内容、自定义端点、对端点进行访问控制等，详情可以参考SpringBoot官方文档。\n引言中的Spring Boot Admin就是通过收集这些metrics，然后展示到UI界面的。\nPrometheus\n革命尚未成功——Spring Boot应用引入Actuator后，具有了指标统计的功能，但还需要强大的监控系统(Spring Boot Admin太弱了)。\n是什么\nhttps:prometheus.iodocsintroductionoverview\n\nPrometheus is an open-source systems monitoring and alerting toolkit originally built at SoundCloud.\n\n\nPrometheus scrapes metrics from instrumented jobs, either directly or via an intermediary push gateway for short-lived jobs. It stores all scraped samples locally and runs rules over this data to either aggregate and record new time series from existing data or generate alerts. Grafana or other API consumers can be used to visualize the collected data.\n\n架构\n\n\nPrometheus Server: Prometheus服务端，由于存储及收集数据，提供相关api对外查询用。\nExporter: 类似传统意义上的被监控端的agent，有区别的是，它不会主动推送监控数据到server端，而是等待server端定时来手机数据，即所谓的主动监控。\nPushagateway: 用于网络不可直达而居于exporter与server端的中转站。比如只会运行短暂时间的应用，无法一直暴露监控数据，就需要先存储在Pushagateway。\nAlertmanager: 报警组件，将报警的功能单独剥离出来放在alertmanager。\nWeb UI: Prometheus的web接口，可用于简单可视化，及语句执行或者服务状态监控。\n\n特性\n\n用多维度数据模型来表示监控数据。监控数据的时间序列由metric名称和键值对标识\nPromQL, 在多维数据模型上的一种灵活的查询语言\n不依赖分布式存储；单个服务器节点是自治的\n时间序列数据通过HTTP PULL收集\n时间序列推送是通过中间网关来支持\n可以通过服务发现或静态配置来发现监控目标\n\n与Spring Boot Actuator建立关系\n\nSpringBoot采用Micrometer统计指标后，通过Micrometer Prometheus Registry暴露指标，并按照要求的格式，供Prometheus服务端抓取，Prometheus提供了存储、报警、查询、高可用等功能。而Grafana则基于Prometheus的功能提供了可视化展示。\n运行\n下载、运行Prometheus Server很简单。官网下载解压后直接运行就可以了。不过在运行之前先看一下Prometheus自己的配置文件初始内容\nprometheus.yml初始内容关键部分：\n1234567891011# A scrape configuration containing exactly one endpoint to scrape:# Here its Prometheus itself.scrape_configs:  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.  - job_name: prometheus    # metrics_path defaults to metrics    # scheme defaults to http.    static_configs:    - targets: [localhost:9090]\nscrape_configs下配置了一个名为prometheus的抓取任务，目标是localhost:9090。\n初始的prometheus.yml中，prometheus服务会默认抓取自身的监控数据。\n我们启动Prometheus（在windows中直接运行prometheus.exe就可以了）\n\n在下拉菜单中可以看到一些监控指标，选中后点击Execute可以查询指标的当前值\n\n还可以切换到Graph卡片，查看折线图\n\n下面，我们学习下如何监控SpringBoot应用。\n监控Spring Boot应用\n在我们之前创建的应用中再加入micrometer-registry-prometheus依赖，该模块可以将micormeter采集到的监控数据，整合成Prometheus要求的格式，然后发布到特定endpoint(默认actuatorprometheus)，供Prometheus Server抓取。即该模块与prometheus架构图中的Jobs对接，Jobs从actuatorprometheus通过HTTP PULL抓取监控数据。\n现在的pom.xml关键部分如下：\n123456789101112131415161718&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;artifactId&gt;    &lt;dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;artifactId&gt;    &lt;dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;        &lt;artifactId&gt;spring-boot-starter-actuator&lt;artifactId&gt;    &lt;dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.micrometer&lt;groupId&gt;        &lt;artifactId&gt;micrometer-registry-prometheus&lt;artifactId&gt;    &lt;dependency&gt;&lt;dependencies&gt;\n运行该Spring Boot应用（server.port: 8089），访问actuatorprometheus，可以看到暴露出的Prometheus格式的数据，\n如果看不到，可能是该endpoint未暴露，可以在yml中配置management.endpoints.web.exposure.include: &quot;*&quot;\n\n接下来配置Prometheus Server，加入一个job，让它抓取该SpringBoot应用的监控数据。\n将prometheus.yml的scape_config改为：\n123456scrape_configs:   \t# 加入一个名为myWebApp的抓取任务，抓取目标是localhost:8089，它的指标暴露在actuatorprometheus  - job_name: myWebApp\tmetrics_path: actuatorprometheus    static_configs:    - targets: [localhost:8089]\n注意，为了方便观察，在上面的配置中，删掉了初始配置文件中的&quot;prometheus&quot;抓取任务。\n重启Prometheus Server，并查询http_server_requests_seconds_count\n\n可以查询到请求次数的图标。\n但是，我们比较关心的有qps、错误率、延时等，这些指标不在监控的原始数据里，因为prometheus收集的是原始数据。所以必须在查询时通过查询语句进行即时计算。参考：速率计算：Server-side Vs Client-side\n比如qps：\nrate(http_server_requests_seconds_count[5m])QPS5分钟均值\n\n更多查询实例可参考官方文档之查询实例\n小结\nPrometheus提供了指标数据手机、监控、计算、报警、展示的功能，但是在UI展示方面还很薄弱，官方也指出，自带的UI界面只是作为特殊查询和调试，对于更加强大的图形界面，还是推荐使用Grafana。\nGrafana\nGrafana 是一款采用 go 语言编写的开源应用，主要用于大规模指标数据的可视化展现，基于商业友好的 Apache License 2.0 开源协议。\n在网络架构和应用分析中最流行的时序数据展示工具，并且也在工业控制、自动化监控和过程管理等领域有着广泛的应用\ngrafana有热插拔控制面板和可扩展的数据源，已经支持绝大部分常用的时序数据库，包含以下：Graphite、Elasticsearch、CloudWatch、InfluxDB、OpenTSDB、Prometheus\n启动\n下载、运行也非常简单，根据官方文档一步步做就好了。要注意的是：\n\nGo into the conf directory and copy sample.ini to custom.ini. You should edit custom.ini, never defaults.ini.\n\n在windows上运行还需要在 custom.ini中需要修改默认的3000端口，比如9999：\n\nThe default Grafana port is 3000, this port requires extra permissions on windows. Edit custom.ini and uncomment the http_port configuration option (; is the comment character in ini files) and change it to something like 8080 or similar. That port should not require extra Windows privileges.\n\n启动Grafana。(windows下直接运行bin目录的grafana-server.exe)\n访问localhost:9999，默认用户名密码都是admin\n\n加入Prometheus数据源\n配置Prometheus相关信息\n\n\n\n加入DashBoard\n可以加入一些预定义的DashBoard，这些DashBoard中配置了许多常用的监控图表，并且已经配置好了对应的查询语句，所以我们可以直接用这些DashBoard就可以查看监控了。\n在https:grafana.comdashboards中查找SpringBoot对应的DashBoard\n\n比如：https:grafana.comdashboards10280\n拷贝DashBoard的Id：10280，在自己的Grafana中加入该DashBoard：\n\n\n\n\n\n\n如果配置好DashBorad后，仍没有监控数据，则需要自己看下加入的dashboard的使用帮助，如刚才加入的dashborad中，有这样一则说明：\n\n需要按照要求配置application。\n点击某个图表的表头，可以对该图图表进行编辑。\n\n可以看到已经预制好的查询语句：\n\n报警\n支持多种形式的报警发送，如邮件、Kafka、钉钉等。关于报警的配置，本文不在过多演示，可以查看官方文档。\n需要注意的是：报警只支持到单图表，无法嵌套模板变量。如图标编辑界面左上角有筛选node的下拉框，图表又传入了变量时，如果配置报警，是配置失败的。报错为：“Template variables are not supported in alert queries”。\n\n官方的解释为：他们找不到一个好的办法来解决歧义性。https:github.comgrafanagrafanaissues7060\n所以想要报警，必须先创建一个不含模板变量的图表，然后针对该图表进行报警配置。\n参考资料\nSpring Boot 2.0官方文档之 Actuator\nbaeldung.comspring-boot-actuators\nhttps:www.jianshu.comp82abd86ef447\nhttps:blog.51cto.comyouerning2050543\nPrometheus与其他监控系统对比，包括Graphite、InfluxDB、Nagios等\n速率计算：Server-side Vs Client-side\n","tags":["Spring-Boot","微服务","Actuator","服务监控"],"path":"2019/06/19/Spring-Boot-Actuator/","external_link":""},{"title":"Hello World","date":"2019-04-30T12:40:31.886Z","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start\nCreate a new post\n1$ hexo new My New Post\nMore info: Writing\nRun server\n1$ hexo server\nMore info: Server\nGenerate static files\n1$ hexo generate\nMore info: Generating\nDeploy to remote sites\n1$ hexo deploy\nMore info: Deployment\n","tags":["hexo","gihub pages"],"path":"2019/04/30/hello-world/","external_link":""},{"title":"Spring Cloud Eureka","date":"2019-06-18T06:45:48.000Z","content":"Eureka 提供基于 REST 的服务，在微服务体系中用于服务管理 。 Eureka 提供了基于 Java语言的客户端组件，客户端组件实现了负载均衡的功能，为业务组件的集群部署与解构提供了便利。使用该框架，可以将业务组件注册到 Eureka 容器中，并且业务组件可进行集群部署， Eureka维护这些服务组件的列表并自动检查它们的状态 。\nSpringBoot版本为2.1.5.RELEASE\nSpringCloud版本为Greenwich.SR1\n\n前言\n关于微服务\n微服务一词来自 Martin Fowler 的 《Microservices》 一文，微服务是一种架构风格，将单体应用划分为小型的服务单元 。在此不做过多讲解。\n关于SpringCloud与Netflix\n关于 Netflix OSS\nNetflix 是一个互联网影片提供商，在几年前， Netflix 公司成立了自己的开源中心， 名称为 Netflix Open Source Software Center，简称 Netflix OSS 。这个开源组织专注于大数据、云计算方面的技术，提供了多个开源框架，这些框架包括大数据工具、构建工具、基于云平台的服务工具等。 Netflix 所提供的这些框架，很好地遵循了微服务所推崇的理念，实现了去中心化的服务管理、服务容错等机制。\nSpring Cloud 与 Netflix\nSpring Cloud 并不是一个具体的框架，大家可以把它理解为一个工具箱，它提供的各类工具 ，可以帮助我们快速构建微服务系统。\nSpring Cloud 的各个项目基于Spring Boot，将Netflix的多个框架进行封装，并且通过自动配置的方式将这些框架绑定到Spring的环境中，从而简化了这些框架的使用 。由于Spring Boot的简便，使得我们在使用Spring Cloud 时，很容易将 Netflix 各个框架整合进项目中。 Spring Cloud下的 Spring Cloud Netflix 模块， 主要封装了 Netflix的以下项目：\n\n\n服务发现Eureka\n\n\n服务熔断Hystrix\n\n\n服务路由Zuul\n\n\n客户端负载均衡Ribbon\n\n\n而除了Netflix提供的模块之外，Spring Cloud还提供了其他模块：\n\n\nSpring Cloud Config：为分布式系统提供了配置服务器和配置客户端，通过对它们\n的配置，可以很好地管理集群中的配置文件。\n\n\nSpring Cloud Sleuth：服务跟踪框架，可以与 Zipkin 、 Apache HTrace 和 ELK 等数据\n分析、服务跟踪系统进行整合，为服务跟踪、解决问题提供了便利 。\n\n\nSpring Cloud Stream：用于构建消息驱动微服务的框架，该框架在 Spring Boot 的基\n础上，整合了 Spring Integration 来连接消息代理中间件。\n\n\nSpring Cloud Bus：连接 RabbitMQ 、 Kafka 等消息代理的集群消息总线 。\n\n\n服务注册与发现Eureka\nWhy Use Service Discovery\nhttps:www.nginx.comblogservice-discovery-in-a-microservices-architecture\n\nLet’s imagine that you are writing some code that invokes a service that has a REST API or Thrift API. In order to make a request, your code needs to know the network location (IP address and port) of a service instance. In a traditional application running on physical hardware, the network locations of service instances are relatively static. For example, your code can read the network locations from a configuration file that is occasionally updated.\nIn a modern, cloud‑based microservices application, however, this is a much more difficult problem to solve as shown in the following diagram.\n\n\n\nService instances have dynamically assigned network locations. Moreover, the set of service instances changes dynamically because of autoscaling, failures, and upgrades. Consequently, your client code needs to use a more elaborate service discovery mechanism.\n\n\nThere are two main service discovery patterns: client‑side discovery and server‑side discovery.\n\nEureka架构\nEureka 提供基于 REST 的服务，在微服务体系中用于服务管理 。 Eureka 提供了基于 Java语言的客户端组件，客户端组件实现了负载均衡的功能，为业务组件的集群部署与解构提供了便利。使用该框架，可以将业务组件注册到 Eureka 容器中，并且业务组件可进行集群部署， Eureka维护这些服务组件的列表并自动检查它们的状态 。\n一个简单的 Eureka 集群，需要一个 Eureka 服务器、若干个服务提供者 。 业务组件作为服务提供者将自己注册到 Eureka 服务器上，其他组件作为Eureka客户端可以向Eureka服务器获取组件列表并且进行远程调用。\n\n图中有3个Eureka服务器，服务器支持集群部署，每个服务器也可以作为对方服务器的客户端进行相互注册与复制。图中共有4个 Eureka 客户端，2个为服务提供者用于发布服务，另2个为服务调用者（或成为消费者） 。 不管是服务器还是客户端，都可以部署多个实例 ，如此一来 ， 就很容易构建高可用的服务集群 。\n构建Eureka服务器\n建议使用Spring Initializr创建。\n\n生成的pom.xml关键部分如下：\n1234567891011121314151617181920212223242526272829303132333435363738   &lt;parent&gt;       &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;       &lt;artifactId&gt;spring-boot-starter-parent&lt;artifactId&gt;       &lt;version&gt;2.1.5.RELEASE&lt;version&gt;       &lt;relativePath&gt; &lt;!-- lookup parent from repository --&gt;   &lt;parent&gt;&lt;properties&gt;       &lt;java.version&gt;1.8&lt;java.version&gt;       &lt;spring-cloud.version&gt;Greenwich.SR1&lt;spring-cloud.version&gt;   &lt;properties&gt;   &lt;dependencies&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;           &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;artifactId&gt;       &lt;dependency&gt;   &lt;dependencies&gt;   &lt;dependencyManagement&gt;       &lt;dependencies&gt;           &lt;dependency&gt;               &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;               &lt;artifactId&gt;spring-cloud-dependencies&lt;artifactId&gt;               &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;version&gt;               &lt;type&gt;pom&lt;type&gt;               &lt;scope&gt;import&lt;scope&gt;           &lt;dependency&gt;       &lt;dependencies&gt;   &lt;dependencyManagement&gt;   &lt;build&gt;       &lt;plugins&gt;           &lt;plugin&gt;               &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;               &lt;artifactId&gt;spring-boot-maven-plugin&lt;artifactId&gt;           &lt;plugin&gt;       &lt;plugins&gt;   &lt;build&gt;\n加入的spring-cloud-starter-netflix-eureka-server 会自动引入 spring-boot-starter-web，因此只需加入该依赖，我们的项目就具有 Web 容器的功能了 。\n在运行主类上加上@EnableEurekaServer代表启动Eureka服务器\n1234567@SpringBootApplication@EnableEurekaServerpublic class LearnEurekaApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(LearnEurekaApplication.class, args);    &#125;&#125;\n本例中并没有配置服务器端口，因此默认端口为 8080 ，我们将端口配置为 8761 ，在mainresources 目录下创建application.yml 配置文件\n12345678910server:  port: 8761# 以下配置是为了防止启动过程中抛出异常eureka:  client:    # 不向Eureka服务器注册自己，因为自己本身就是服务器，若要注册自己时，还未启动完成，会报错    registerWithEureka: false    # 不用从服务器中抓取注册信息    fetchRegistry: false\n启动该Spring Boot应用，打开浏览器，输入 http:localhost:8761 ，可以看到 Eureka器控制台，如下图所示：\n\n编写服务提供者\n还是使用Spring Initializr创建\n\npom.xml\n12345678910111213141516   &lt;parent&gt;       ...同上   &lt;parent&gt;&lt;dependencies&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;           &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;artifactId&gt;       &lt;dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;           &lt;artifactId&gt;spring-boot-starter-web&lt;artifactId&gt;       &lt;dependency&gt;   &lt;dependencies&gt;   &lt;dependencyManagement&gt;       ...同上   &lt;dependencyManagement&gt;\napplication.yml\n1234567891011server:  port: 8080spring:  application:    name: service-producereureka:  client:    serviceUrl:      defaultZone: http:localhost:8761eureka  instance:    hostname: localhost\n以上配置中，将应用名称配置为service-provider ，该服务将会被注册到端口为 8761的 Eureka 服务器，也就是本节前面所构建的服务器 。另外，还使用了 eureka.instance.hostname来配置该服务实例的主机名称。\nGreetingController.java\n编写一个 Controller ， 并提供一个最简单的 REST接口来模拟提供的服务\n1234567891011@RestControllerpublic class GreetingController &#123;    @Value($&#123;server.port&#125;)    private int port;    @GetMapping(greeting)    public String greeting() &#123;        return hello from provider  + port;    &#125;&#125;\n在运行主类上加上@EnableEurekaServer代表启动Eureka客户端\n1234567@SpringBootApplication@EnableEurekaClientpublic class LearnEurekaProviderApplication  &#123;    public static void main(String[] args) &#123;        SpringApplication.run(LearnEurekaProviderApplication.class, args);    &#125;&#125;\n运行该SpringBoot应用两次，两次的yml中分别配置server.port为8080和8081。运行后在此查看Eureka控制台：\n\n注意到Instances列表中显示，服务SERVICE-PRODUCER有两个状态为UP的实例。\n关于EMERGENCY! EUREKA MAY BE INCORRECTLY ......可以参考自我保护模式 \n编写服务调用者\n下面，我们编写一个服务调用者，它会通过Eureka来获取服务的地址，并进行调用。\n使用Spring Initializr创建，此处与创建服务提供者时相同，都是勾选Spring Web Starter与Eureka Discovery Client。最终的pom文件也都一样。\n创建一个Service层，它调用其他服务模块（在这里就是我们刚才编写的service-producer）提供的服务。\n123456789101112@Servicepublic class MyService &#123;    @Autowired    RestTemplate restTemplate;    public String getGreetingStr() &#123;         调用服务名为service-producer服务提供者的greeting接口        return restTemplate.getForObject(http:service-producergreeting, \t\t\t\t\t \t\t\t\t\t\t\t\t String.class);    &#125;&#125;\n需要注意的是，调用服务时，仅需要通过服务名称进行调用，不需要服务提供者真正的主机名或者IP。\n为了验证服务提供者返回的结果，我们创建一个Controller方便我们查看。\n1234567891011@RestControllerpublic class MyController &#123;    @Autowired    private MyService myService;    @GetMapping()    public String getGreeting()&#123;        return myService.getGreetingStr();    &#125;&#125;\n注意，在MyService中使用的restTemplate需要我们手动配置。我们在主类中一起进行配置。\n123456789101112131415@SpringBootApplication@EnableDiscoveryClient public class LearnEurekaConsumerApplication &#123;    @Bean    @LoadBalanced    RestTemplate restTemplate() &#123;        return new RestTemplate();    &#125;    public static void main(String[] args) &#123;        SpringApplication.run(LearnEurekaConsumerApplication.class, args);    &#125;&#125;\nRestTemplate 本来是 spring-web 模块下面的类，主要用来调用 REST 服务。本身并不具备调用分布式服务的能力，但是 RestTemplate的 Bean 被＠Loac!Balanced 注解修饰后，这个 RestTemplate 实例就具有访问分布式服务的能力了。\n另外，在启动类中，使用了＠EnableDiscoveryClient 注解，该注解使得服务调用者有能力去 Eureka 中发现服务。需要注意的是，我们在服务提供者中用到的＠EnableEurekaClient 注解其实包含了@EnableDiscoveryClient 的功能，也就是说，一个 Eureka 客户端，本身就具有发现服务的能力。\napplication.yml\n12345678910server:  port: 9000spring:  application:    name: service-consumereureka:  client:    service-url:      defaultZone: http:localhost:8761eureka\n运行该SpringBoot应用，多访问几次localhost:9000，可以交替获得hello from provider 8080和hello from provider 8081。\n其实内部是使用Ribbon组件做的客户端负载均衡。相关知识可参考Ribbon官方文档。\n总结下，当前建立的项目之间的调用结构如下：\n\n搭建Eureka服务器集群\n现在改造之前的项目，搭建Eureka集群，实现高可用\n修改Eureka服务器配置\n修改Eureka服务器项目的application.yml。利用配置文件的profiles特性\n1234567891011121314151617181920212223242526272829303132333435363738394041424344# 修改spring.profiles.active执行生效的profile，single对应单Eureka服务器# 如要启动Eureka服务器集群，则改为eureka1和eureka2分别运行spring:  profiles:    active: eureka1eureka:  client:    registerWithEureka: false    fetchRegistry: false---server:  port: 8761spring:  profiles: single---server:  port: 8762spring:  application:    name: firest-cloud-server  profiles: eureka1eureka:  instance:    hostname: eureka1  client:    serviceUrl:      defaultZone: http:eureka2:8763eureka---server:  port: 8763spring:  application:    name: second-cloud-server  profiles: eureka2eureka:  instance:    hostname: eureka2  client:    serviceUrl:      defaultZone: http:eureka1:8762eureka\n修改hosts文件中设置eureka1和eureka2的映射。\n将spring.profiles.active指定为eureka1和eureka2分别运行程序，两个Eureka服务端实例将分别运行在http:eureka1:8762和http:eureka2:8763。\n修改服务提供者配置\n同理修改application.yml\n12345678910111213141516171819202122232425262728spring:  application:    name: service-producer  profiles:    active: cluster-eurekaserver:  port: 8080---eureka:  client:    serviceUrl:      defaultZone: http:localhost:8761eureka  instance:    hostname: localhostspring:  profiles: single-eureka---eureka:  client:    serviceUrl:      defaultZone: http:eureka1:8762eureka,http:eureka2:8763eureka  instance:    preferIpAddress: truespring:  profiles: cluster-eureka\n将spring.profiles.active指定为cluster-eureka，并将server.port指定为8080和8081分别启动。\n修改服务消费者配置\n123456789101112131415161718192021222324server:  port: 9000spring:  application:    name: service-consumer  profiles:    active: cluster-eureka---spring:  profiles: single-eurekaeureka:  client:    service-url:      defaultZone: http:localhost:8761eureka---spring:  profiles: cluster-eurekaeureka:  client:    service-url:      defaultZone: http:eureka1:8762eureka,http:eureka2:8763eureka\n将spring.profiles.active指定为cluster-eureka，并运行。\n分别查看两个Eureka服务端实例：\n\n\n当前的调用关系如下图，EurekaSever实例之间会相互注册、同步信息，而每个EurekaClient只需向一个EurekaServer注册：\n\n服务健康自检\n在默认情况下， Eureka 的客户端每隔 30 秒会发送一次心跳给服务器端，告知它仍然存活。但是，在实际环境中有可能出现这种情况，客户端表面上可以正常发送心跳，但实际上服务是不可用的。\n例如一个需要访问数据的服务提供者，表面上可以正常响应，但是数据库己经无法访问：又如，服务提供者需要访问第三方的服务，而这些服务早己失效。对于这些情况，应当告诉服务器当前客户 的状态，调用者或者其他客户端无法获取这些有问题的实例 。 实现该功能，可以使用 Eureka 的健康检查控制器。\n在服务提供者的pom.xml中加入:\n1234&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;artifactId&gt;&lt;dependency&gt;\n简单起见，在这里不使用Eureka服务器集群。\n所以将application.yml中的spring.profiles.active指定为cluster-eureka，server.port为8080\n将eureka-service项目的application.yml的spring.profiles.active指定为single\n先启动eureka-service，再启动producer。\n访问localhost:8761的eureka控制台\n\n再访问http:localhost:8080actuatorhealth\n\n自定义应用健康自检\n假设需要检查数据库是否连接正常，来判断当前服务是否可用，我们需要做两件事：\n\n让客户端自己进行检查，是否能连接数据库 ；\n将连接数据库的结果与客户端的状态进行关联， 并且将状态告诉Eureka服务器。\n\n实现一个自定义的 Healthlndicator，根据是否能访问数据库，来决定应用自身的健康。\n123456789101112131415@Componentpublic class MyHealthIndicator implements HealthIndicator &#123;    public static int DB_ERROR = 1001;    @Override    public Health health() &#123;        if (GreetingController.canVisitDb) &#123;            成功连接数据库，返回 UP            return new Health.Builder(Status.UP).build();        &#125; else &#123;            连接数据库失败，返回 out of service            return Health.down().withDetail(连接数据库失败, DB_ERROR).build();        &#125;    &#125;&#125;\n为了简单起见，使用 GreetingController类的 canVisitDb 变量来模拟是否能连接上数据库 ,并且我们可以使用REST接口进行动态改变该值。\n123456789101112131415@RestControllerpublic class GreetingController &#123;    public static volatile Boolean canVisitDb = true;    @GetMapping(greeting)    public String greeting() &#123;        return hello from provider-with-health-indicator;    &#125;    @GetMapping(canVisitDb&#123;canVisitDb&#125;)    public String setCanVisitDb(@PathVariable Boolean canVisitDb) &#123;        GreetingController.canVisitDb = canVisitDb;        return 当前数据库是否正常： + GreetingController.canVisitDb;    &#125;&#125;\n接下来，如果服务提供者想把健康状态告诉服务器，还需要实现 HealthCheckHandler。处理器会将应用的健康状态保存到内存中，状态一旦发生改变，就会重新向服务器进行注册，其他的客户端将拿不到这些不可用的实例。\n12345678910111213141516@Componentpublic class MyHealthCheckHandler implements HealthCheckHandler &#123;    @Autowired    private MyHealthIndicator indicator; 注入了前面编写的健康指示器    @Override    public InstanceInfo.InstanceStatus getStatus(InstanceInfo.InstanceStatus instanceStatus) &#123;        Status s = indicator.health().getStatus();        if (s.equals(Status.UP)) &#123;            return InstanceInfo.InstanceStatus.UP;        &#125; else &#123;            return InstanceInfo.InstanceStatus.DOWN;        &#125;    &#125;&#125;\nEureka 中会启动一个定时器，定时刷新本地实例的信息，并且执行“处理器 ”中的 getStatus 方法，再将服务实例的状态“更新”到服务器中。执行以上逻辑的定时器 ， 默认 30 秒执行一次，如果想加快看到效果，可以修改 eureka.client.instancelnfoReplicationlntervalSeconds 配置。\n启动Eureka服务器，再启动当前带健康自检的服务提供者(8081)，和之前的一个不带健康自检的服务提供者(8080)，再启动一个服务消费者(9000端口)。\n多访问几次localhost:9000，可以看到，两个会轮询调用两个服务提供者：\n\n访问 localhost: 8080canVisitDbfalse，模拟将数据库设为不可用。\n再访问 8761 端口在浏览器中访 问 http:localhost:8761 ， 可看到服务提供者的状态为 DOWN。\n\n稍等几秒后，访问几次localhost:9000，发现只会出现&quot;hello from provider 8080&quot;，也就是说消费者将不再调用状态为DOWN的服务提供者实例。\n常用配置\n心跳检测\n\n客户端的实例会向服务器发送周期性的心跳，默认30秒一次，可以修改客户端的eureka.instance.leaseRenewalIntervalInSeconds属性来改变这个时间。\n服务器端接收心跳请求，如果在一定期限内没有接收到服务实例的心跳，那么会将该实例从注册表中清理掉，其他的客户端将会无法访问这个实例。这个期限默认值为90秒，可以通过修改eureka.instance.leaseExpirationDurationlnSeconds属性来改变这个值。也就是说，服务器90秒没有收到客户端的心跳，就会将这个实例从列表中清理掉。但需要注意的是，清理注册表有一个定时器在执行，默认是60秒执行一次，如果将leaseExpirationDurationlnSeconds设置为小于60秒，虽然符合删除实例的条件，但是还没到60秒，这个实例将仍然存在注册表中（因为还没有执行清理）。我们可以在Eureka服务器端配置eureka.server.eviction-interval-timer-in-ms属性来修改注册表的清理间隔。\n需要特别注意，如果开启了自我保护模式，则实例不会被剔除。在测试时，为避免受自我保护模式的影响，建议先关闭自我保护模式，在Eureka服务器端配置：eureka.server.enable-self-preservation=false\n\n注册表抓取时间\n\n在默认情况下，客户端每隔30秒去服务器端抓取注册表（可用的服务列表），并且将服务器端的注册表保存到本地缓存中。可以通过修改eureka.client.registryFetchIntervalSeconds配置来改变注册表抓取间隔，但仍然需要考虑性能，改为哪个值比较合适，需要在性能与实时性方面进行权衡。\n\n配置与使用元数据\n框架自带的元数据，包括实例 id 、 主机名称、 E 地址等，如果需要自定义元数据并提供给其他客户端使用，可以配置 eureka.instance.metadata-map 属性来指定。元数据都会保存在服务器的注册表中，并且使用简单的方式与客户端进行共享。在正常情况下，自定义元数据不会改变客户端的行为，除非客户端知道这些元数据的含义，以下配置片断使用了元数据 。\n12345eureka :  instance:    hostname: localhost    metadata-map:      company-name: abc\n配置了一个名为 company-name 的元数据，值为 abc，使用元数据的一方，可以调用DiscoveryClient 的方法获取元数据，如以下代码所示 ：\n12345678910111213@Autowiredprivate DiscoveryClient discoveryClient;@RequestMapping(value = greeting, method = RequestMethod.GET)public String greeting() &#123;\t 查询服务实例    List&lt;Serviceinstance&gt; ins = discoveryClient.getInstances(heart-beat-client);\t 遍历实例并输出元数据值    for (Serviceinstance service : ins) &#123;        System.out.println(service.getMetadata().get(company-ηame））;        return hello from xxx;    &#125;&#125;\n自我保护模式\n在开发过程中 ，经常可以在 Eureka 的主界面中看到红色字体的提醒，内容如下：\nEMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE.\n出现该提示意味着 Eureka 进入了自我保护模式。根据前面章节的介绍可知，客户端会定时发送心跳给服务器端，如果心跳的失败率超过一定比例，服务会将这些实例保护起来，并不会马上将其从注册表中剔除。此时对于另外的客户端来说，有可能会拿到一些无法使用的实例，这种情况可能会导致灾难的“蔓延”，这些情况可以使用容错机制予以解决， 关于集群的容错机制，将在后面的章节中讲述 。 在开发过程中，为服务器配置eureka.server.enable-self-preservation属性，将值设置为 false 来关闭自我保护机制 。关闭后再打开 Eureka 主界面，可以看到以下提示信息：\nTHE SELF PRESERVATION MODE IS TURNED OFF. THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORKOTHER PROBLEMS.\n自我保护模式己经关闭，在出现网络或者其他问题时，将不会保护过期的实例。\n相关原理\n以下摘自https:github.comNetflixeurekawikiEureka-at-a-glance\nResilience\nEureka clients are built to handle the failure of one or more Eureka servers. Since Eureka clients have the registry cache information in them, they can operate reasonably well, even when all of the eureka servers go down.\nEureka Servers are resilient to other eureka peers going down. Even during a network partition between the clients and servers, the servers have built-in resiliency to prevent a large scale outage.\nHow different is Eureka from AWS ELB?\nAWS Elastic Load Balancer is a load balancing solution for edge services exposed to end-user web traffic. Eureka fills the need for mid-tier load balancing. While you can theoretically put your mid-tier services behind the AWS ELB, in EC2 classic you expose them to the outside world and there by losing all the usefulness of the AWS security groups.\nAWS ELB is also a traditional proxy-based load balancing solution whereas with Eureka it is different in that the load balancing happens at the instanceserverhost level. The client instances know all the information about which servers they need to talk to. This is a blessing or a curse depending on which way you look at it. If you are looking for a sticky user session based load balancing which AWS now offers, Eureka does not offer a solution out of the box. At Netflix, we prefer our services to be stateless (non-sticky). This facilitates a much better scalability model and Eureka is well suited to address this.\nAnother important aspect that differentiates proxy-based load balancing from load balancing using Eureka is that your application can be resilient to the outages of the load balancers, since the information regarding the available servers is cached on the client. This does require a small amount of memory, but buys better resiliency.\nUnderstanding-eureka-client-server-communication\n以下摘自https:github.comNetflixeurekawikiUnderstanding-eureka-client-server-communication\nThe Eureka client interacts with the server the following ways.\nRegister\nEureka client registers the information about the running instance to the Eureka server.\nRegistration happens on first heartbeat (after 30 seconds).\nRenew\nEureka client needs to renew the lease by sending heartbeats every 30 seconds. The renewal informs the Eureka server that the instance is still alive. If the server hasn’t seen a renewal for 90 seconds, it removes the instance out of its registry. It is advisable not to change the renewal interval since the server uses that information to determine if there is a wide spread problem with the client to server communication.\nFetch Registry\nEureka clients fetches the registry information from the server and caches it locally. After that, the clients use that information to find other services. This information is updated periodically (every 30 seconds) by getting the delta updates between the last fetch cycle and the current one. The delta information is held longer (for about 3 mins) in the server, hence the delta fetches may return the same instances again. The Eureka client automatically handles the duplicate information.\nAfter getting the deltas, Eureka client reconciles the information with the server by comparing the instance counts returned by the server and if the information does not match for some reason, the whole registry information is fetched again. Eureka server caches the compressed payload of the deltas, whole registry and also per application as well as the uncompressed information of the same. The payload also supports both JSONXML formats. Eureka client gets the information in compressed JSON format using jersey apache client.\nCancel\nEureka client sends a cancel request to Eureka server on shutdown. This removes the instance from the server’s instance registry thereby effectively taking the instance out of traffic.\nUnderstanding-Eureka-Peer-to-Peer-Communication\n以下摘自https:github.comNetflixeurekawikiUnderstanding-Eureka-Peer-to-Peer-Communication\nEureka clients tries to talk to Eureka Server in the same zone. If there are problems talking with the server or if the server does not exist in the same zone, the clients fail over to the servers in the other zones.\nOnce the server starts receiving traffic, all of the operations that is performed on the server is replicated to all of the peer nodes that the server knows about. If an operation fails for some reason, the information is reconciled on the next heartbeat that also gets replicated between servers.\nWhen the Eureka server comes up, it tries to get all of the instance registry information from a neighboring node. If there is a problem getting the information from a node, the server tries all of the peers before it gives up. If the server is able to successfully get all of the instances, it sets the renewal threshold that it should be receiving based on that information. If any time, the renewals falls below the percent configured for that value (below 85% within 15 mins), the server stops expiring instances to protect the current instance registry information.\nIn Netflix, the above safeguard is called as self-preservation mode and is primarily used as a protection in scenarios where there is a network partition between a group of clients and the Eureka Server. In these scenarios, the server tries to protect the information it already has. There may be scenarios in case of a mass outage that this may cause the clients to get the instances that do not exist anymore. The clients must make sure they are resilient to eureka server returning an instance that is non-existent or un-responsive. The best protection in these scenarios is to timeout quickly and try other servers.\nIn the case, where the server is not able get the registry information from the neighboring node, it waits for a few minutes (5 mins) so that the clients can register their information. The server tries hard not to provide partial information to the clients there by skewing traffic only to a group of instances and causing capacity issues.\nEureka servers communicate with one another using the same mechanism used between the Eureka client and the server as described here.\nWhat happens during network outages between Peers?\nIn the case of network outages between peers, following things may happen\n\nThe heartbeat replications between peers may fail and the server detects this situation and enters into a self-preservation mode protecting the current state.\nRegistrations may happen in an orphaned server and some clients may reflect new registrations while the others may not.\nThe situation autocorrects itself after the network connectivity is restored to a stable state. When the peers are able to communicate fine, the registration information is automatically transferred to the servers that do not have them.\n\nThe bottom line is, during the network outages, the server tries to be as resilient as possible, but there is a possibility of clients having different views of the servers during that time.\nZookeeper与Eureka优劣比较\nhttps:blog.csdn.netzipoarticledetails60588647\nhttps:my.oschina.netu3677987blog2885801\n参考资料\nSpringCloud Netflix 文档\n《疯狂Spring Cloud微服务架构实战》\nUnderstanding-eureka-client-server-communication\nclient‑side discovery and server‑side discovery\nself‑registration pattern and third‑party registration pattern\nservice-discovery-in-a-microservices-architecture\n","tags":["微服务","Spring-Cloud","Eureka","服务发现"],"path":"2019/06/18/Spring-Cloud-Eureka/","external_link":""}]';

	s = s.replace(/\\n/g, "\\n")
               .replace(/\\'/g, "\\'")
               .replace(/\\"/g, '\\"')
               .replace(/\\&/g, "\\&")
               .replace(/\\r/g, "\\r")
               .replace(/\\t/g, "\\t")
               .replace(/\\b/g, "\\b")
               .replace(/\\f/g, "\\f")

// remove non-printable and other non-valid JSON chars
	s = s.replace(/[\u0000-\u0019]+/g,"");
	var list = JSON.parse(s);
	var fuse = new Fuse(list, options);
	var el = document.getElementById('search-form');
	var newBox = $('.Card-archive').first().clone();
	el.oninput = function(event){
		var searchText = el.value;
		var result = fuse.search(searchText);
		$('.archive-cards .Card-archive').remove();
		for(var i in result){
			var anotherBox = newBox.clone();
			var dateStr = new Date(result[i].date);
			anotherBox.css('display','flex');
			var url = "";
			if(result[i].external_link !== ""){
				url = result[i].external_link;
			}else{
				url = '/' + result[i].path;
			}

			anotherBox.find('.Card-title a').text(result[i].title).attr('href', url);
			anotherBox.find('.Card-date').text(dateStr.toDateString());
			anotherBox.appendTo('.archive-cards');
		}
	}
</script>

<div class="tagcloud-container">
<div class="tag-cloud">
	<a href="/tags/Actuator/" style="font-size: 0.8em; color: #488baf">Actuator</a> <a href="/tags/Eureka/" style="font-size: 0.8em; color: #488baf">Eureka</a> <a href="/tags/Java8/" style="font-size: 2em; color: #d63e0a">Java8</a> <a href="/tags/Lambda/" style="font-size: 0.8em; color: #488baf">Lambda</a> <a href="/tags/Spring-Boot/" style="font-size: 0.8em; color: #488baf">Spring-Boot</a> <a href="/tags/Spring-Cloud/" style="font-size: 0.8em; color: #488baf">Spring-Cloud</a> <a href="/tags/Stream/" style="font-size: 0.8em; color: #488baf">Stream</a> <a href="/tags/gihub-pages/" style="font-size: 0.8em; color: #488baf">gihub pages</a> <a href="/tags/hexo/" style="font-size: 0.8em; color: #488baf">hexo</a> <a href="/tags/微服务/" style="font-size: 1.4em; color: #8f655d">微服务</a> <a href="/tags/服务发现/" style="font-size: 0.8em; color: #488baf">服务发现</a> <a href="/tags/服务监控/" style="font-size: 0.8em; color: #488baf">服务监控</a>
</div>
</div>

  </div>

  

<footer id="footer">
    <div class="footer-copyright">
        <div>
            <p> Copyright by <a href>Li JunFeng </a> @ 2019</p>
            <p>Designed by: <i class="fas fa-paint-brush"></i> <a href="https://moober.cn">Moober</a> and <i class="fas fa-graduation-cap"></i> <a href="https://qutang.github.io">Qu Tang</a> &bull; Theme: <a href="https://qutang.github.io/cutie/">Cutie 2.1.3-Taurus</a> &bull; Powered by <a href="http://hexo.io">Hexo.</a></p>
        </div>
    </div>
    
    <div class="footer-social">
        
            
                
                    <div class="footer-social-item"><a href="https://github.com/lijunfeng722" target="_blank"><i class="fab fa-github fa-2x" aria-hidden="true"></i></a></div>
                
            
        
    </div>
</footer>

  <br>

  <div id="footer-nav" class='footer-nav'>
		



<nav id="nav">
	
	
	
	<div class="nav-item" id="nav-item-archive">
		
				<div class="nav-icon">
				
			<a href="/archives/" title="Archives">
			<img src="/images/icons/colorful-outlined/archive.svg" alt>
			</a>
		</div>
	</div>
	<div class="nav-item" id="nav-item-search">
		
		<div class="nav-icon active_dot">
		
			<a href="/search/" title="Search">
			<img src="/images/icons/colorful-outlined/search.svg" alt>
			</a>
		</div>
	</div>
	<div class="nav-item" id="nav-item-more">
		<div class="nav-icon">
				<a href="#" onclick="onClickMenuIcon(event);" ontouchstart="onClickMenuIcon(event);">
				<img src="/images/icons/colorful-outlined/menu.svg" alt>
				</a>
		</div>
		<div class="nav-more-menu">
				<i class="far fa-times-circle" id="nav-more-menu-close" onclick="onClickNavMenuClose(event);" ontouchstart="onClickNavMenuClose(event);"></i>
		
		
		<div class="nav-more-item">
				<div class="nav-name">
					<a class="nav-link" href="/categories/Java/">
						<span>Java</span>
					</a>
				</div>
		</div>
		
		<div class="nav-more-item">
				<div class="nav-name">
					<a class="nav-link" href="/categories/Spring-Boot/">
						<span>Spring-boot</span>
					</a>
				</div>
		</div>
		
		<div class="nav-more-item">
				<div class="nav-name">
					<a class="nav-link" href="/categories/Spring-Cloud/">
						<span>Spring-cloud</span>
					</a>
				</div>
		</div>
		
	</div>
	</div>
</nav>

	</div>

  



    
    
    
    
<script>
    new Valine({
        el: '#valine',
        notify:false, 
        verify:false,
        appId: 'V0jTkst5qpMeK7oHyQYwLB85-gzGzoHsz',
        appKey: 'rWMxYnrvsMGqWwJFbczwXkPY',
        placeholder: 'write your comment',
        path:window.location.pathname, 
        avatar:'retro',
        lang: 'en'
    });
</script>













<script type="text/javascript">

  
</script>


    
<script type="text/javascript">
  
</script>

<script type="application/javascript" src="https://api.ipify.org?format=jsonp&callback=getIP"></script>



<!-- <script src="/js/post.js"></script> -->

<script src="/js/headroom.min.js"></script>

<script data-no-instant type="text/javascript">

initHeadroom();

changeLayoutOnTouchScreen();

// 
</script>


<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
